{"meta":{"title":null,"subtitle":"Talk is cheap. Show me the code","description":"","author":"Hairui Wang","url":"https://onehr7.github.io","root":"/"},"pages":[{"title":"404","date":"2021-01-14T14:30:49.000Z","updated":"2021-01-14T14:31:07.401Z","comments":true,"path":"/404.html","permalink":"https://onehr7.github.io/404.html","excerpt":"","text":""},{"title":"about","date":"2021-03-19T14:51:14.000Z","updated":"2021-03-19T14:51:30.472Z","comments":true,"path":"about/index.html","permalink":"https://onehr7.github.io/about/index.html","excerpt":"","text":""},{"title":"categories","date":"2021-01-14T14:28:34.000Z","updated":"2021-03-19T14:50:20.423Z","comments":true,"path":"categories/index.html","permalink":"https://onehr7.github.io/categories/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2023-01-08T12:16:22.144Z","updated":"2023-01-08T11:44:30.614Z","comments":true,"path":"links/index.html","permalink":"https://onehr7.github.io/links/index.html","excerpt":"","text":""},{"title":"tags","date":"2021-01-14T14:25:46.000Z","updated":"2021-03-19T14:50:47.595Z","comments":true,"path":"tags/index.html","permalink":"https://onehr7.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Python字节码分析两值互换","slug":"Python字节码分析两值互换","date":"2022-11-07T15:02:15.000Z","updated":"2022-11-07T15:43:10.167Z","comments":true,"path":"2022/11/07/Python字节码分析两值互换/","link":"","permalink":"https://onehr7.github.io/2022/11/07/Python%E5%AD%97%E8%8A%82%E7%A0%81%E5%88%86%E6%9E%90%E4%B8%A4%E5%80%BC%E4%BA%92%E6%8D%A2/","excerpt":"在Python的语法中，可以在一行中不通过临时变量，即可交换变量。如：a, b = b, a。 在直觉上，a, b = b, a与b, a = a, b得到的a, b值应当相等。但在实际中，如果a, b 在赋值过程中，存在引用关系的情况下，则得到值就会有差异，以下是一次字节码的详细分析。","text":"在Python的语法中，可以在一行中不通过临时变量，即可交换变量。如：a, b = b, a。 在直觉上，a, b = b, a与b, a = a, b得到的a, b值应当相等。但在实际中，如果a, b 在赋值过程中，存在引用关系的情况下，则得到值就会有差异，以下是一次字节码的详细分析。 假设有一个数组为 nums = [1, 2, 3, 4]，此时执行nums[0], nums[1] = nums[1], nums[0]后，不难得出nums变为[2, 1, 3, 4] 但如果执行nums[nums[1]], nums[1] = nums[1], nums[nums[1]]和nums[1], nums[nums[1]] = nums[nums[1]], nums[1], 此时nums的值将不太能确定。 以下使用Python3.8对nums[0], nums[1] = nums[1], nums[0]对执行过程进行分析 import dis def test(): nums = [1, 2, 3, 4] nums[0], nums[1] = nums[1], nums[0] dis.dis(test) # 得到nums[0], nums[1] = nums[1], nums[0]行的执行过程为 24 LOAD_FAST 0 (nums) 26 LOAD_CONST 1 (1) 28 BINARY_SUBSCR 30 LOAD_FAST 0 (nums) 32 LOAD_CONST 5 (0) 34 BINARY_SUBSCR 36 ROT_TWO 38 LOAD_FAST 0 (nums) 40 LOAD_CONST 5 (0) 42 STORE_SUBSCR 44 LOAD_FAST 0 (nums) 46 LOAD_CONST 1 (1) 48 STORE_SUBSCR 50 LOAD_CONST 0 (None) 52 RETURN_VALUE # co_consts (None, 1, 2, 3, 4, 0) # co_varnames ('nums',) 字节码说明 code DESC LOAD_FAST 将指向局部对象 co_varnames[var_num] 的引用推入栈顶。 LOAD_CONST 将 co_consts[consti] 推入栈顶。 BINARY_SUBSCR 先POP得到k值,再对栈顶执行 d = d[k] ROT_TWO 交换两个最顶层的堆栈项。 STORE_SUBSCR 实现 TOS1[TOS] = TOS2 。再将栈顶头三个移出 RETURN_VALUE 返回 TOS 到函数的调用者。 得出流程图为 可以看出，在等号两边执行时，都为从左到右执行。 # 因此分析以下赋值结果 nums = [1, 2, 3, 4] nums[nums[1]], nums[1] = nums[1], nums[nums[1]] nums[nums[1]], nums[1] = 2, 3 nums[2], nums[1] = 2, 3 nums = [1, 3, 2, 4] nums = [1, 2, 3, 4] nums[1], nums[nums[1]] = nums[nums[1]], nums[1] nums[1], nums[nums[1]] = 3, 2 nums[1] = 3 nums[3] = 2 nums = [1, 3, 3, 2]","categories":[{"name":"Python","slug":"Python","permalink":"https://onehr7.github.io/categories/Python/"}],"tags":[{"name":"字节码","slug":"字节码","permalink":"https://onehr7.github.io/tags/%E5%AD%97%E8%8A%82%E7%A0%81/"}]},{"title":"ClickHouse优化（译） -- 跳数索引","slug":"ClickHouse优化（译） -- 跳数索引","date":"2022-11-04T14:02:15.000Z","updated":"2022-11-04T14:09:19.817Z","comments":true,"path":"2022/11/04/ClickHouse优化（译） -- 跳数索引/","link":"","permalink":"https://onehr7.github.io/2022/11/04/ClickHouse%E4%BC%98%E5%8C%96%EF%BC%88%E8%AF%91%EF%BC%89%20--%20%E8%B7%B3%E6%95%B0%E7%B4%A2%E5%BC%95/","excerpt":"原文 理解 ClickHouse 跳数索引跳数索引简介许多因素都会影响 ClickHouse 的查询性能。大多数场景下的关键因素是判断 ClickHouse 在查询时在WHERE 子句条件中是否可以使用主键。因此，选择适用于最常见查询模式的主键对于高效的表设计至关重要。 尽管如此，无论主键如何精心调优，都难免会出现无法使用主键的查询用例。用户通常依赖 ClickHouse 获取时间序列类型的数据，但他们通常希望根据其他业务维度分析相同的数据，例如客户 ID、网站 URL 或产品编号。在这种情况下，查询性能可能会相当差，因为可能需要对每个列值进行完整的扫描才能应用 WHERE 子句条件。虽然 ClickHouse 在这些情况下仍然相对较快，但评估数百万或数十亿个单独的值将导致“无索引”查询的执行速度比基于主键的查询慢得多。 在传统关系型数据库中，解决此问题的一种方法是将一个或多个“辅助”索引添加到表中。这是一种 b-tree数据结构，它允许数据库以 O(log(n)) 而不是 O(n)（全表扫描） 时间复杂度中找到磁盘上的所有匹配行，其中 n 是行数。但是这种类型的辅助索引不适用于 ClickHouse（或其他列式数据库），因为磁盘上没有单独的行可以添加到索引中。 相反，ClickHouse 提供了一种在特定情况下可以显著提高查询速度的与众不同的索引。这种结构被命名为“跳数”索引，因为它们使 ClickHouse 能够跳过读取确定没有匹配值的重要数据块。","text":"原文 理解 ClickHouse 跳数索引跳数索引简介许多因素都会影响 ClickHouse 的查询性能。大多数场景下的关键因素是判断 ClickHouse 在查询时在WHERE 子句条件中是否可以使用主键。因此，选择适用于最常见查询模式的主键对于高效的表设计至关重要。 尽管如此，无论主键如何精心调优，都难免会出现无法使用主键的查询用例。用户通常依赖 ClickHouse 获取时间序列类型的数据，但他们通常希望根据其他业务维度分析相同的数据，例如客户 ID、网站 URL 或产品编号。在这种情况下，查询性能可能会相当差，因为可能需要对每个列值进行完整的扫描才能应用 WHERE 子句条件。虽然 ClickHouse 在这些情况下仍然相对较快，但评估数百万或数十亿个单独的值将导致“无索引”查询的执行速度比基于主键的查询慢得多。 在传统关系型数据库中，解决此问题的一种方法是将一个或多个“辅助”索引添加到表中。这是一种 b-tree数据结构，它允许数据库以 O(log(n)) 而不是 O(n)（全表扫描） 时间复杂度中找到磁盘上的所有匹配行，其中 n 是行数。但是这种类型的辅助索引不适用于 ClickHouse（或其他列式数据库），因为磁盘上没有单独的行可以添加到索引中。 相反，ClickHouse 提供了一种在特定情况下可以显著提高查询速度的与众不同的索引。这种结构被命名为“跳数”索引，因为它们使 ClickHouse 能够跳过读取确定没有匹配值的重要数据块。 基本操作用户只能在 MergeTree 表系列上使用跳数索引。每个索引数据都有四个主要参数： 索引名称。索引名称用于在每个分区中创建索引文件。此外，在删除或应用索引时需要它作为参数。 索引表达式。索引表达式用于计算存储在索引中的集合值。它可以是列、简单运算符和且/或组成的由索引类型确定的函数的子集。 类型。索引的类型控制确定是否可以跳过读取和评估每个索引块的计算量。 粒度。每个索引块由 GRANULARITY 粒度组成。例如，如果表主键的粒度为 8192 行，并且索引粒度为 4，则每个索引的“块”将为 32768 行。 当用户创建跳数索引时，表的每个分区目录中都会创建两个附加文件。 skpidx{index_name}.idx，其中包含有序的表达式值） skpidx{index_name}.mrk2，其中包含相关数据列文件的相应偏移量。 如果 WHERE 子句的部分过滤条件在执行查询和读取相关列文件时与跳数索引表达式匹配时，ClickHouse 将使用索引文件数据来确定每个相关数据块是否必须处理或可以绕过（假设该块尚未被主键排除）。使用下表加载可测试的数据， 测试一个简单的示例。 CREATE TABLE skip_table ( my_key UInt64, my_value UInt64 ) ENGINE MergeTree primary key my_key SETTINGS index_granularity=8192; INSERT INTO skip_table SELECT number, intDiv(number,4096) FROM numbers(100000000); 在执行不使用主键的简单查询时，my_value 会扫描列中的所有 1 亿条数据： SELECT * FROM skip_table WHERE my_value IN (125, 700) ┌─my_key─┬─my_value─┐ │ 512000 │ 125 │ │ 512001 │ 125 │ │ ... | ... | └────────┴──────────┘ 8192 rows in set. Elapsed: 0.079 sec. Processed 100.00 million rows, 800.10 MB (1.26 billion rows/s., 10.10 GB/s. 现在添加一个非常基本的跳数索引： ALTER TABLE skip_table ADD INDEX vix my_value TYPE set(100) GRANULARITY 2; 通常跳数索引只应用于新插入的数据，所以只添加索引不会影响上面的查询。 要使索引应用到现有数据，请使用以下语句： ALTER TABLE skip_table MATERIALIZE INDEX vix; 使用新创建的索引重新运行查询： SELECT * FROM skip_table WHERE my_value IN (125, 700) ┌─my_key─┬─my_value─┐ │ 512000 │ 125 │ │ 512001 │ 125 │ │ ... | ... | └────────┴──────────┘ 8192 rows in set. Elapsed: 0.051 sec. Processed 32.77 thousand rows, 360.45 KB (643.75 thousand rows/s., 7.08 MB/s.) ClickHouse 没有处理800 M的1亿行数据，而是只读取分析了360 KB 的 32768 行数据——四个粒度，每个粒度 8192 行。 在更直观的表现中，这是my_value如何读取和选择 a 为 125 的 4096 行的方式，以及在不从磁盘读取的情况下如何跳过以下行： 用户可以通过在执行查询时启用跟踪，来记录有关跳数索引使用情况的详细信息。在 clickhouse-client 中，设置 send_logs_level： SET send_logs_level='trace'; 这将在尝试优化查询SQL 和表索引时提供有用的调试信息。在上面的示例中，调试日志显示了跳数索引跳过了除两个粒度数据之外的所有粒度数据： default.skip_table (933d4b2c-8cea-4bf9-8c93-c56e900eefd1) (SelectExecutor): Index `vix` has dropped 6102/6104 granules. 跳数索引类型minmax这种轻量级索引类型不需要参数。它存储每个块的索引表达式的最小值和最大值（如果表达式是元组，它单独存储元组元素的每个成员的值）。这种类型非常适合按值松散排序的列。这种索引类型通常在查询处理期间处理成本最低。 这种类型的索引仅适用于标量或元组表达式——索引永远不会应用于返回数组或map数据类型的表达式。 set这种轻量级索引类型接受每个块设置的值的 max_size 的单个参数（0 允许无限数量的离散值）。此集合包含块中的所有值（如果值的数量超过 max_size，则为空）。这种索引类型适用于每组粒度中基数较低的列（本质上是“聚集在一起”），但总体上基数较高。 该索引的成本、性能和有效性取决于块内的基数。如果每个块都包含大量的唯一值，要么针对大型索引集查询条件成本非常大，要么由于超过 max_size 导致索引为空而不会应用索引。 布隆过滤器布隆过滤器是一种数据结构，它允许以少量误差为代价对集合成员进行节省空间。在跳数索引的情况下，误差不是一个重要的考虑因素，因为唯一的缺点是读取了一些不必要的块。但是，可能存在的误差确实意味着索引表达式应该是正确的，否则可能会跳过有效数据。 由于布隆过滤器可以更有效地处理大量离散值的数据，所以它们适用于产生大量值的条件表达式。尤其是通过使用 mapKeys 或 mapValues 函数将键或值转换为数组，可以将布隆过滤器索引应用于数组（其中测试数组的每个值）和maps。 基于布隆过滤器的数据跳数索引类型共有三种： 基本的bloom_filter，它使用0到1之间允许的“误差”率的单个可选参数（如果未指定，则使用0.025）。 专门的tokenbf_v1。它需要三个参数，所有参数都与调整使用的布隆过滤器有关：（1）过滤器的大小（以字节为单位）（较大的过滤器要具有较小的误差，需要在存储方面有一定的消耗），（2）应用的哈希函数的数量（同样，更多的哈希函数能减少误差），以及（3）布隆过滤器哈希函数的seed。有关这些参数如何影响布隆过滤器功能的更多详细信息，请参阅此处的计算公式。此索引仅适用于 String、FixedString 和 Map 数据类型。输入表达式被拆分为由非字母数字字符分隔的字符序列。例如，列值This is a candidate for a &quot;full text&quot; search将包含序列This is a candidate for full text search. 它旨在用于 LIKE、EQUALS、IN、hasToken() 和类似搜索中较长字符串中的单词和其他值。例如，一种可能的用途可能是在一列自由格式的应用程序日志行中搜索少量的类名或行号。 专门的ngrambf_v1。该索引的功能与tokenbf_v1索引相同。它在布隆过滤器设置之前需要一个额外参数，即索引的 ngram 的大小。ngram 是长度为n的字符串的任意子串，因此大小为4的ngram的字符串A short string将被索引为： 'A sh', ' sho', 'shor', 'hort', 'ort ', 'rt s', 't st', ' str', 'stri', 'trin', 'ring' 此索引还可用于文本搜索，尤其是没有分词的语言，例如中文。 跳数索引函数跳数索引的核心目的是限制常用查询分析的数据量。鉴于 ClickHouse 数据的分析性质，在大多数情况下，这些查询的模式包括函数表达式。因此，跳数索引必须与常用函数正确交互才能有效。这可能在以下情况下发生： • 插入数据并将索引定义为函数表达式（表达式的结果存储在索引文件中），或者 • 处理查询并将表达式应用于存储的索引值以确定是否排除该块。 每种类型的跳数索引都适用于此处列出的索引实现的可用 ClickHouse 函数的子集 。通常，集合索引和基于布隆过滤器的索引（另一种集合索引）都是无序的，因此不适用于范围。相反，由于确定范围是否相交非常快，因此 minmax 索引在确定范围上应用得特别好。部分匹配函数 LIKE、startsWith、endsWith 和 hasToken 的功能取决于使用的索引类型、索引表达式和数据特征。 跳数索引设置两个适用于跳数索引的可用设置。 use_skip_indexes （0 或 1，默认为 1）。并非所有查询都可以有效地使用跳数索引。如果一个特定的过滤条件可能包括大多数粒度，则不必要应用跳数索引，有时甚至是巨大的成本。对于不太可能从任何跳数索引中受益的查询，请将该值设置为 0。 force_data_skipping_indexes（以逗号分隔的索引名称列表）。此设置可用于防止某些类型的低效查询。在查询表除非使用跳数索引， 否则过于笨重的情况下，将此设置一个或多个索引名称，将在不使用列出的索引的任何查询情况下返回异常。这将防止编写不佳的查询消耗服务器资源。 跳数索引最佳实践跳过索引并不直观，特别是对于习惯于使用 RDMS 领域中的基于行的二级索引或文档存储中的反向索引的用户而言。为了获得任何优化，应用 ClickHouse跳数索引必须避免足够的粒度读取来抵消计算索引的成本。至关重要的是，如果一个值在索引块中出现一次，则意味着必须将整个块读入内存进行计算，并且不必要地产生了索引成本。 考虑以下数据分布： 假设主键/排序键是timestamp，并且在visitor_id上有一个索引。考虑以下查询： SELECT timestamp, url FROM table WHERE visitor_id = 1001 对于这种数据分布，传统的二级索引将非常有利。二级索引不会读取所有 32678 行来查找满足请求的 visitor_id 的 5 行，而是仅包含五个行位置，并且只会从磁盘读取这五行。对于 ClickHouse 跳数索引，情况正好相反。visitor_id无论跳过索引的类型如何，都将扫描列中的所有 32678 个值。 因此，通过简单地向关键列添加索引来尝试优化ClickHouse 查询的想法通常是不正确的。此高级功能仅应在调查其他替代方案后使用，例如修改主键（参考如何选择主键）、使用投影或使用物化视图。即使跳数索引是合适的，通常也需要仔细调整索引和表。 在大多数情况下，有用的跳数索引需要主键和目标非主键列/表达式之间的强相关性。如果没有相关性（如上图），则几千个值的块中至少有一行满足过滤条件的几率很高，导致跳过少数块。相反，如果主键的值范围（如一天中的时间）与潜在索引列中的值（如电视观众年龄）密切相关，那么 minmax 类型的索引可能是有益的。请注意，在插入数据时可能会增加这种相关性，方法是在排序/ORDER BY 键中包含其他列，或者以与主键关联的值在插入时分组的方式批量插入。例如，即使主键是包含来自大量站点的事件的时间戳，也可以将特定 site_id 的所有事件分组并写入到一起。这将导致许多粒度仅包含几个站点 ID，因此在按特定 site_id 值搜索时可能会跳过许多块。 跳数索引的另一个很好的应用场景是高基数表达式，其中任何一个值在数据中都相对稀疏。一个示例是跟踪 API 请求中的错误代码的可观察性平台。某些错误代码虽然在数据中很少见，但对于搜索可能特别重要。在 error_code 列上设置跳数索引将允许绕过绝大多数不包含错误的块，从而显着改善以错误为中心的查询。 最后，关键的最佳实践是测试、测试和再次测试。同样，与用于搜索文档的 b-tree 二级索引或反向索引不同，跳数索引行为不易预测。将它们添加到表中会在数据摄取和由于多种原因而无法从索引中受益的查询上产生巨大的成本。它们应该始终在线上环境的数据上进行测试，并且测试应该包括类型、粒度大小和其他参数的变化。测试通常会揭示仅从猜想实验中看不到的不明显模式和陷阱。","categories":[{"name":"ClickHouse","slug":"ClickHouse","permalink":"https://onehr7.github.io/categories/ClickHouse/"}],"tags":[]},{"title":"ClickHouse优化（译） -- 主键索引","slug":"ClickHouse优化（译） -- 主键索引","date":"2022-11-02T14:02:15.000Z","updated":"2022-11-04T14:05:18.389Z","comments":true,"path":"2022/11/02/ClickHouse优化（译） -- 主键索引/","link":"","permalink":"https://onehr7.github.io/2022/11/02/ClickHouse%E4%BC%98%E5%8C%96%EF%BC%88%E8%AF%91%EF%BC%89%20--%20%E4%B8%BB%E9%94%AE%E7%B4%A2%E5%BC%95/","excerpt":"原文 介绍ClickHouse 稀疏主键索引的最佳实践在本文中，我们将深入研究 ClickHouse 索引。我们将详细说明以下问题： ClickHouse 中的索引与传统的关系型数据库索引有何不同 ClickHouse是 如何构建和使用表的稀疏主键索引的 在 ClickHouse 中建立索引的一些最佳案例是什么","text":"原文 介绍ClickHouse 稀疏主键索引的最佳实践在本文中，我们将深入研究 ClickHouse 索引。我们将详细说明以下问题： ClickHouse 中的索引与传统的关系型数据库索引有何不同 ClickHouse是 如何构建和使用表的稀疏主键索引的 在 ClickHouse 中建立索引的一些最佳案例是什么 您可以选择在自己的机器上自行执行本文中给出的所有 ClickHouse SQL 语句和查询。有关 ClickHouse 的安装和入门说明，请参阅快速入门。 本文重点介绍 ClickHouse 稀疏主键索引。 对于 ClickHouse跳数索引，请参阅此教程。 数据集通过本次教程，我们将使用一个匿名的Web 流量数据集作为示例。 我们将使用样本数据集中 887 万行（事件）的子数据集。 未压缩的数据大小大约为 700 MB，并包含887 万个事件。当存储在 ClickHouse 中时，它会被压缩到 200 MB。 在我们的子数据集中，每行包含三列：网络用户（UserID）在特定时间（EventTime）点击了一条URL（URL） 通过这三列，我们已经可以制定一些典型的 Web 分析查询，例如： 指定用户的点击次数排名前10的网址是哪些？ 指定URL 的前10 位活跃用户是哪些？ 用户点击指定URL 的最通常的时间（例如一周中的哪几天）是什么时候？ 测试机器本文档给出的所有运行数据，均基于在配备 Apple M1 Pro 芯片和 16GB RAM 的 MacBook Pro 上本地运行的ClickHouse 22.2.1。 全表扫描为了展现如何在不使用主键的情况下，对我们的数据集执行查询。我们通过执行以下 SQL DDL 语句来创建一个表（使用 MergeTree 表引擎）： CREATE TABLE hits_NoPrimaryKey ( `UserID` UInt32, `URL` String, `EventTime` DateTime ) ENGINE = MergeTree PRIMARY KEY tuple(); 接下来使用以下 SQL 插入语句将hits数据集的子数据插入到表中。通过URL 表函数与结构推断结合使用，以加载在 clickhouse.com 远程托管的完整数据集的子集： INSERT INTO hits_NoPrimaryKey SELECT intHash32(c11::UInt64) AS UserID, c15 AS URL, c5 AS EventTime FROM url('https://datasets.clickhouse.com/hits/tsv/hits_v1.tsv.xz') WHERE URL != ''; 响应如下： Ok. 0 rows in set. Elapsed: 145.993 sec. Processed 8.87 million rows, 18.40 GB (60.78 thousand rows/s., 126.06 MB/s.) ClickHouse 客户端的输出结果表明，上面的语句向表中成功写入了 887 万行。 最后，为了简化本文后面的讨论，并使图表和结果可重现，我们使用 FINAL 关键字[optimize] 表： OPTIMIZE TABLE hits_NoPrimaryKey FINAL; 通常，不需要也不建议在将数据加载到表后立即对其进行optimize 。但这对于这个例子为什么有必要则是显而易见的。 现在执行我们的第一个web分析查询。以下是计算 ID 为 749927693 的互联网用户的点击次数前 10 的网址： SELECT URL, count(URL) as Count FROM hits_NoPrimaryKey WHERE UserID = 749927693 GROUP BY URL ORDER BY Count DESC LIMIT 10; 结果如下： ┌─URL────────────────────────────┬─Count─┐ │ http://auto.ru/chatay-barana.. │ 170 │ │ http://auto.ru/chatay-id=371...│ 52 │ │ http://public_search │ 45 │ │ http://kovrik-medvedevushku-...│ 36 │ │ http://forumal │ 33 │ │ http://korablitz.ru/L_1OFFER...│ 14 │ │ http://auto.ru/chatay-id=371...│ 14 │ │ http://auto.ru/chatay-john-D...│ 13 │ │ http://auto.ru/chatay-john-D...│ 10 │ │ http://wot/html?page/23600_m...│ 9 │ └────────────────────────────────┴───────┘ 10 rows in set. Elapsed: 0.022 sec. Processed 8.87 million rows, 70.45 MB (398.53 million rows/s., 3.17 GB/s.) ClickHouse 客户端的输出结果表明， ClickHouse 执行了全表扫描！我们表的 887 万行中的每一行都流式传输到了ClickHouse。这是行不通的。 为了使这种查询更有效并且更快，我们需要使用具有适当主键的表。这将允许 ClickHouse 自动（基于主键的列）创建稀疏主键索引，然后可以使用该索引明显加快示例查询的执行速度。 ClickHouse 索引设计海量数据规模下的索引设计在传统的关系型数据库中，表的每一行都包含一个主键索引。对于我们的数据集，这将导致主键索引: 通常是B(+)-Tree数据结构，包含 887 万条。 这样的索引可以快速定位指定行，从而提高查询和定点更新的效率。在 B(+)-Tree 数据结构中查找索引的平均时间复杂度为O(log2 n)。对于 887 万行的表，这意味着只需要23 次搜索就能定位任何索引项。 这种能力是有代价的：在向表添加新行和向索引中添加项时（有时还会重新平衡 B-Tree），会产生额外的磁盘和内存开销，以及更高的插入成本。 考虑到与 B-Tree 索引相关的挑战，ClickHouse 中的表引擎采用了不同的方法。ClickHouse MergeTree 引擎系列经过设计和优化，可处理大量数据。 这些表旨在每秒接收数百万行插入并且存储非常大（100 PB+）的数据量。 数据被快速的逐块写入表，并在后台应用规则合并各块。 在 ClickHouse 中，每个数据块都有自己的主键索引。当数据块被合并时，合并部分的主键索引也被合并。 在 ClickHouse 设计的数据规模非常大的情况下，最重要的是要非常高效地使用磁盘和内存。因此，数据块的主键索引不是对每一行都进行索引，而是在每组行数据（称为“粒度”）中有一个索引项（称为“mark”）。 这种稀疏索引是能实现的，因为 ClickHouse 将数据块的行存储在按主键列排序的磁盘上。 稀疏索引不是直接定位单行（如基于 B-Tree 的索引），而是通过它快速（通过对索引项的二分搜索）识别可能与查询匹配的行组。 然后将定位的潜在匹配行（粒度）组并行的流式传输到 ClickHouse 引擎中以找到匹配项。 这种索引设计允许索引很小（它可以而且必须完全满足主内存），同时仍然显着加快查询执行时间：特别是对于数据分析用例中典型的范围查询。 下面详细说明 ClickHouse是如何构建和使用稀疏索引的。稍后在本文中，我们将讨论一些如何选择、删除和排序用于构建索引的表列（主键列）的最佳实践。 具有主键的表创建一个具有复合主键的表，其中包含键列 UserID 和 URL： CREATE TABLE hits_UserID_URL ( `UserID` UInt32, `URL` String, `EventTime` DateTime ) ENGINE = MergeTree PRIMARY KEY (UserID, URL) ORDER BY (UserID, URL, EventTime) SETTINGS index_granularity = 8192, index_granularity_bytes = 0; DDL语句详情 为了简化本文后面的探索，并使图表和结果可重现，DDL 声明为 通过ORDER BY子句为表指定组合排序键 通过以下设置显式控制主键索引将具有的索引项： index_granularity：显式设置为其默认值 8192。这意味着对于每组的 8192 行，主键索引将包含一个索引项，例如，如果表包含 16384 行，那么索引将有两个索引项。 index_granularity_bytes：设置为 0 以禁用自适应索引粒度。自适应索引粒度意味着 ClickHouse 自动为一组 n 行数据创建一个索引项 如果 n 小于 8192，但该 n 行的组合行数据的大小大于或等于 10 MB（index_granularity_bytes 的默认值）或 如果 n 行的组合行数据大小小于 10 MB，但 n 为 8192。 通过上面 DDL 语句中的主键索引声明，将基于两个指定列创建主键索引。 接下来写入数据： INSERT INTO hits_UserID_URL SELECT intHash32(c11::UInt64) AS UserID, c15 AS URL, c5 AS EventTime FROM url('https://datasets.clickhouse.com/hits/tsv/hits_v1.tsv.xz') WHERE URL != ''; 响应如下所示： 0 rows in set. Elapsed: 149.432 sec. Processed 8.87 million rows, 18.40 GB (59.38 thousand rows/s., 123.16 MB/s.) 然后optimize表： OPTIMIZE TABLE hits_UserID_URL FINAL; 我们可以使用以下查询来获取有关我们表的元数据： SELECT part_type, path, formatReadableQuantity(rows) AS rows, formatReadableSize(data_uncompressed_bytes) AS data_uncompressed_bytes, formatReadableSize(data_compressed_bytes) AS data_compressed_bytes, formatReadableSize(primary_key_bytes_in_memory) AS primary_key_bytes_in_memory, marks, formatReadableSize(bytes_on_disk) AS bytes_on_disk FROM system.parts WHERE (table = 'hits_UserID_URL') AND (active = 1) FORMAT Vertical; 结果如下： part_type: Wide path: ./store/d9f/d9f36a1a-d2e6-46d4-8fb5-ffe9ad0d5aed/all_1_9_2/ rows: 8.87 million data_uncompressed_bytes: 733.28 MiB data_compressed_bytes: 206.94 MiB primary_key_bytes_in_memory: 96.93 KiB marks: 1083 bytes_on_disk: 207.07 MiB 1 rows in set. Elapsed: 0.003 sec. ClickHouse 客户端的输出表明： 表数据以宽格式存储在磁盘上的特定目录中，这意味着该目录中的每个表列将有一个数据文件（和一个标记文件）。 该表有 887 万行。 所有行的未压缩数据大小合计为 733.28 MB。 所有行的压缩磁盘数据大小合计为 206.94 MB。 该表有一个包含 1083 项（称为“mark”）的主键索引，索引的大小为 96.93 KB。 表的数据和标记文件以及主键索引文件总共占用了 207.07 MB 磁盘空间。 数据按主键列顺序存储在磁盘上我们在上面创建的表包含有 组合主键 (UserID, URL) 组合排序键 (UserID, URL, EventTime) 如果我们只指定排序键，那么主键将被隐式定义为排序键。 为了提高内存效率，我们明确的指定了一个主键，它只包含我们查询需要过滤的列。因为基于主键的索引会被完全加载到主存中。 为了使文章的图表中保持一致性，并为了最大限度地提高压缩率，我们定义了一个单独的排序键，其中包括我们表的所有列（如果在一列中相似的数据彼此接近，例如通过排序，那么数据将被更好地压缩）。 如果两者都指定，则主键必须为排序键的前缀。 插入的行按主键列（以及排序键中的附加 EventTime 列）按字典顺序（升序）存储在磁盘上。 ClickHouse 允许插入具有相同主键列值的多行。在这种情况下（参见下图中的第 1 行和第 2 行），最终顺序由指定的排序键决定，因此由EventTime列的值决定。 ClickHouse 是一个面向列的数据库管理系统。如下图所示 对于磁盘来说，表的每个列都有一个数据文件（*.bin），其中该列的所有值都以压缩格式存储。 887 万行按主键列（和附加的排序键列）按字典升序存储在磁盘上，即在这种情况下 首先由UserID排序， 然后通过URL排序， 最后是EventTime排序： UserID.bin、URL.bin 和 EventTime.bin 是磁盘上的数据文件，其中存储了UserID、URL和EventTime列的值。 注意 由于主键定义了磁盘上行的字典顺序，因此一张表只能有一个主键。 我们从 0 开始对行进行编号，以便与 ClickHouse 内部行编号结构对齐，该方案也用于记录消息。 数据被分成粒度以进行并行数据处理出于数据处理的目的，一个表的列值在逻辑上被划分为粒度组。粒度组是ClickHouse 进行流式数据处理的最小不可分割的数据集。这意味着，ClickHouse 不是读取单个行，而是始终读取（以流式和并行方式）整个组（粒度组）的行数据。 列值并不是实际存储在粒度组内部：粒度组只是用于查询处理的列值的 逻辑 组织。 下图说明了我们表的 887 万行（列值）是如何被组织成 1083 个粒度组的，这是由于表的 DDL 语句设置了index_granularity（设置为其默认值 8192）。 第一个（基于磁盘上的物理顺序）8192 行（它们的列值）逻辑上属于粒度 0，然后接下来的 8192 行（它们的列值）属于粒度1，依此类推。 注意 最后一个粒度组（粒度值1082）“包含”少于 8192 行。 我们将主键列（UserID、URL）中的一些列值标记为橙色。 这些橙色标记的列值是每个粒度组中每个主键列的最小值。这里的例外是我们标记最后一个粒度组（上图中的1082粒度组）的最大值。 正如我们将在下面看到的，这些橙色标记的列值将是表的主键索引中的索引项。 我们从 0 开始对粒度组进行编号，以便与 ClickHouse 内部编号方案保持一致，该方案也用于记录消息。 主键索引每个粒度组有一个索引项主键索引是基于上图所示的粒度组创建的。该索引是一个未压缩的扁平化数组文件 (primary.idx)，包含从 0 开始的所谓数字索引标记。 如下图显示，索引文件存储了每个粒度组的最小主键列值（上图中橙色标记的值）。例如 第一个索引项（下图中的’mark 0’）存储上图中粒度组0的主键列的最小值， 第二个索引项（下图中的’mark 1’）存储上图中粒度组1的主键列的最小值，依此类推。 我们的表总共有 1083 个索引项，887 万行数据和 1083 个粒度组： 注意 最后一个索引项（上图中的’mark 1082’）是存储上图中粒度组1082的主键列的最大值。 索引项（索引标记）不是基于我们表中的特定行，而是基于粒度组。例如，对于上图中的索引项’mark 0’，我们的表中没有UserID为240.923且URL为”goal://metry=10000467796a411…”的行。相反，表中有一个粒度组 0，其中在该粒度组中，最小 UserID 值为240.923，最小 URL 值为“goal://metry=10000467796a411…”，这两个值来自不同的行。 主键索引文件被完全加载到主内存中。如果文件大于可用的内存空间，那么ClickHouse 将抛出错误。 主键索引项被称为索引标记，因为每个索引项都标记特定数据范围的最小值。对于示例表： UserID索引标记： 主键索引中存储的UserID值按升序排列。上图中的“mark 1”因此代表了在粒度组 1 中的所有行的UserID值，以及在所有后续粒度组中，都保证大于或等于 4.073.710。 正如我们稍后将看到的，当查询在主键的第一列上进行过滤时，这种全局顺序使 ClickHouse 能够在第一个主键列的索引标记上使用二分查找算法。 URL 索引标记：主键列UserID和URL的基数非常相似，这意味着第一列之后的所有主键列的索引标记通常只代表每个粒度组的数据范围。例如，上图中的URL列的’mark 0’表示粒度组0中所有行的URL值都保证大于等于goal://metry=10000467796a411 …。但是，对于粒度组1中所有行的URL值则不能给出同样的保证，因为UserID列的“mark 1”与“mark 0”具有不同的 UserID 值。 稍后我们将更详细地讨论这对查询执行性能的影响。 主键索引用于选择粒度组我们现在可以在主键索引的支持下执行以下查询。 下面计算UserID 为 749927693 点击次数前十的 url。 SELECT URL, count(URL) AS Count FROM hits_UserID_URL WHERE UserID = 749927693 GROUP BY URL ORDER BY Count DESC LIMIT 10; 响应如下： ┌─URL────────────────────────────┬─Count─┐ │ http://auto.ru/chatay-barana.. │ 170 │ │ http://auto.ru/chatay-id=371...│ 52 │ │ http://public_search │ 45 │ │ http://kovrik-medvedevushku-...│ 36 │ │ http://forumal │ 33 │ │ http://korablitz.ru/L_1OFFER...│ 14 │ │ http://auto.ru/chatay-id=371...│ 14 │ │ http://auto.ru/chatay-john-D...│ 13 │ │ http://auto.ru/chatay-john-D...│ 10 │ │ http://wot/html?page/23600_m...│ 9 │ └────────────────────────────────┴───────┘ 10 rows in set. Elapsed: 0.005 sec. Processed 8.19 thousand rows, 740.18 KB (1.53 million rows/s., 138.59 MB/s.) ClickHouse 客户端的输出此时说明，不是进行全表扫描，而是只有 8190行数据流式传输到 ClickHouse。 如果启用了跟踪日志，ClickHouse 服务器日志文件将显示 ClickHouse 正在对 1083 个 UserID 索引标记执行二分查找，从而找到可能包含 UserID 列值为749927693的行的粒度组。这需要平均时间复杂度为O(log2 n)的 19 个步骤： ...Executor): Key condition: (column 0 in [749927693, 749927693]) ...Executor): Running binary search on index range for part all_1_9_2 (1083 marks) ...Executor): Found (LEFT) boundary mark: 176 ...Executor): Found (RIGHT) boundary mark: 177 ...Executor): Found continuous range in 19 steps ...Executor): Selected 1/1 parts by partition key, 1 parts by primary key, 1/1083 marks by primary key, 1 marks to read from 1 ranges ...Reading ...approx. 8192 rows starting from 1441792 我们从上面的跟踪日志中可以看出，1083 个现有标记中的一个标记满足查询。 跟踪日志细节 标记 176 被识别（包含“找到的左边界标记”，排除“找到的右边界标记”），因此来自粒度 176 的所有 8192 行（从第 1.441.792 行开始 - 我们将在稍后看到）流式传输到 ClickHouse 中，以查找 UserID 列值为749927693的实际行。 我们还可以通过在示例查询中使用EXPLAIN 子句来重现这一点： EXPLAIN indexes = 1 SELECT URL, count(URL) AS Count FROM hits_UserID_URL WHERE UserID = 749927693 GROUP BY URL ORDER BY Count DESC LIMIT 10; 响应如下所示： ┌─explain───────────────────────────────────────────────────────────────────────────────┐ │ Expression (Projection) │ │ Limit (preliminary LIMIT (without OFFSET)) │ │ Sorting (Sorting for ORDER BY) │ │ Expression (Before ORDER BY) │ │ Aggregating │ │ Expression (Before GROUP BY) │ │ Filter (WHERE) │ │ SettingQuotaAndLimits (Set limits and quota after reading from storage) │ │ ReadFromMergeTree │ │ Indexes: │ │ PrimaryKey │ │ Keys: │ │ UserID │ │ Condition: (UserID in [749927693, 749927693]) │ │ Parts: 1/1 │ │ Granules: 1/1083 │ └───────────────────────────────────────────────────────────────────────────────────────┘ 16 rows in set. Elapsed: 0.003 sec. 客户端输出表明1083 个粒度组中的一个被选为可能包含 UserID 列值为 749927693 的行。 结论当对作为组合主键的一部分且是第一个主键列进行查询过滤时，ClickHouse 将在主键列的索引标记上运行二分查找算法。 如上所述，ClickHouse 正在使用其稀疏主键索引来快速（通过二分查找）选择可能包含与查询匹配的行的粒度组。 这是 ClickHouse 执行查询的第一阶段（粒度组选择）。 在第二阶段（数据读取），ClickHouse 定位到选定的粒度组，以便将它们的所有行数据流式传输到 ClickHouse 引擎，从而找到实际匹配查询的行。 我们接下来将再更详细地讨论第二阶段。 标记文件用于定位粒度组下图展示了我们表的主键索引文件的一部分。 如上所述，通过对索引的 1083 个UserID标记进行二分搜索，识别出标记 176。因此，其对应的粒度组176 可能包含 UserID 列值为 749.927.693 的行。 粒度组选择细节 上图显示，标记 176 是第一个匹配的索引项，其中粒度组 176 的最小 UserID 值小于 749.927.693，并且下一个标记（标记 177）的粒度组177 的最小 UserID 值大于此值。因此，只有176 标记对应的粒度组可能包含 UserID 列值为 749.927.693 的行。 为了确定（或不确定）粒度组 176 中的某些行包含 UserID 列值为749.927.693 ，属于该粒度组的所有 8192 行都需要流式传输到 ClickHouse。 为此，ClickHouse 需要知道粒度组 176 的物理位置。 在 ClickHouse 中，我们表的所有粒度组的物理位置都存储在标记文件中。与数据文件类似，每个列都有一个标记文件。 下图展示了三个标记文件 UserID.mrk、URL.mrk 和 EventTime.mrk，它们存储了表的 UserID、URL 和 EventTime 列的粒度组的物理位置。 我们已经讨论了主键索引为什么是一个扁平的未压缩数组文件 (primary.idx)，其中包含从 0 开始编号的索引标记。 同样，标记文件也是一个扁平未压缩的数组文件 (*.mrk)，其中包含从 0 开始编号的标记。 一旦 ClickHouse 识别并选择了可能包含查询匹配行的粒度组的索引标记，就可以在标记文件中执行查找数组位置，以获得粒度组的实际物理位置。 特定列的每个标记文件项都以偏移量的形式存储两个位置： 第一个偏移量（上图中的“block_offset”）用于在压缩列数据文件中定位块，包含所选粒度组的压缩版本。该压缩块可能包含一些压缩粒度组。定位的压缩文件块在读取时被解压到主内存中。 标记文件的第二个偏移量（上图中的“granule_offset”）提供了未压缩块数据中颗粒的位置。 然后将被定位的未压缩粒度的所有 8192 行流式传输到 ClickHouse 以进行进一步处理。 为什么用标记文件 为什么主索引不直接包含索引标记对应的粒度的物理位置？ 因为在 ClickHouse 的非常大的数据规模下，十分重要的是磁盘和内存高效使用。 主索引文件需要加载到主内存。 对于我们的示例查询，ClickHouse 使用了主索引并选择了一个可能包含与我们的查询匹配的行的单个粒度。只有对于那个粒度，ClickHouse 才需要物理位置，以便流式传输相应的行以进行进一步处理。 此外，仅 UserID 和 URL 列需要此偏移信息。 查询中未使用的列不需要偏移信息，例如 EventTime。 对于我们的示例查询，Clickhouse 只需要 UserID 数据文件 (UserID.bin) 中粒度 176 的两个物理位置偏移量和 URL 数据文件 (URL.data) 中粒度 176 的两个物理位置偏移量。 标记文件的存在，间接地避免了在主索引中直接存储所有三列的所有 1083 个粒度的物理位置的条目：从而避免在主内存中存在不必要的（可能未使用的）数据。 下图和下面的文本说明了我们的示例是如何查询 ClickHouse 在 UserID.bin 数据文件中定位粒度 176的。 我们在本文前面讨论过 ClickHouse选择了主索引标记 176，因此粒度 176 可能包含我们查询的匹配行。 ClickHouse 现在使用从索引中选择的标记编号 (176) 在 UserID.mrk 标记文件中进行数组的位置查找，以获得用于定位颗粒 176 的两个偏移量。 如图所示，第一个偏移量是在 UserID.bin 数据文件中定位压缩文件块，该文件包含粒度 176 的压缩版本。 一旦定位的文件块被解压到主内存中，标记文件的第二个偏移量可用于在未压缩数据中定位粒度176。 ClickHouse 需要从 UserID.bin 数据文件和 URL.bin 数据文件中定位（并从其中流式传输所有值）粒度 176 以执行我们的示例查询（UserID 为749.927. 693的互联网用户的前 10 个点击次数最多的 url )。 上图展示了 ClickHouse 如何定位 UserID.bin 数据文件的粒度。 此外，ClickHouse 对 URL.bin 数据文件的粒度 176 执行相同的操作。将两个各自的粒度对齐，并流式传输到 ClickHouse 引擎中进行进一步处理，即对 UserID 为 749.927.693 的所有行的每个组的 URL 值进行聚合和计数，最后按降序输出最大的 10 个 URL 组。 使用多个主键索引辅助键是否有效当查询对复合主键的一部分并且是第一个键列进行过滤时，ClickHouse 将在键列的索引标记上执行二分搜索算法。 但是，当查询对复合主键的一部分但不是第一个键列进行过滤时会发生什么？ 注意 我们讨论一个查询保证不是在第一个键列上过滤，而是在辅助键列上过滤的场景。 当查询同时对第一个键列和第一个键列之后的任何键列进行过滤时，ClickHouse 将对第一个键列的索引标记执行二分搜索。 我们使用一个查询来计算最常点击 URL”http ://public_search”的前 10 个用户： SELECT UserID, count(UserID) AS Count FROM hits_UserID_URL WHERE URL = 'http://public_search' GROUP BY UserID ORDER BY Count DESC LIMIT 10; 响应如下： ┌─────UserID─┬─Count─┐ │ 2459550954 │ 3741 │ │ 1084649151 │ 2484 │ │ 723361875 │ 729 │ │ 3087145896 │ 695 │ │ 2754931092 │ 672 │ │ 1509037307 │ 582 │ │ 3085460200 │ 573 │ │ 2454360090 │ 556 │ │ 3884990840 │ 539 │ │ 765730816 │ 536 │ └────────────┴───────┘ 10 rows in set. Elapsed: 0.086 sec. Processed 8.81 million rows, 799.69 MB (102.11 million rows/s., 9.27 GB/s.) 客户端的输出表明 ClickHouse 几乎执行了全表扫描，尽管URL 列作为复合主键的一部分！ClickHouse 从表的 887 万行中读取了 881 万行。 如果启用了trace_logging，则 ClickHouse 服务器日志文件显示 了ClickHouse 对 1083 个 URL 索引标记使用了通用排除搜索，以识别可能包含 URL 列值为“http: //public_search”的行的那些粒度： ...Executor): Key condition: (column 1 in ['http://public_search', 'http://public_search']) ...Executor): Used generic exclusion search over index for part all_1_9_2 with 1537 steps ...Executor): Selected 1/1 parts by partition key, 1 parts by primary key, 1076/1083 marks by primary key, 1076 marks to read from 5 ranges ...Executor): Reading approx. 8814592 rows with 10 streams 我们可以在上面的示例跟踪日志中看到，1083 个粒度中的 1076 个（通过标记）被选择为可能包含具有匹配 URL 值的行。 这导致 881 万行被流式传输到 ClickHouse 引擎（并行使用 10 个流），以识别实际包含 URL 值“http: //public_search”的行。 然而，正如我们稍后将看到的那样，在选定的 1076 个粒度中只有 39 个粒度实际上包含匹配的行。 虽然基于复合主键 (UserID, URL) 的主索引对于加快具有特定 UserID 值的行的查询过滤非常有用，但该索引在加快过滤具有特定 URL 值的行的查询方面没有提供重要帮助。 原因是 URL 列不是第一个键列，因此 ClickHouse 在 URL 列的索引标记上使用通用排除搜索算法（而不是二分搜索），并且该算法的效率取决于URL 列和它的前置键列 UserID的 基数差异。 为了说明这一点，我们给出了一些关于通用排除搜索是如何执行的细节。 通用排除搜索算法下面说明了ClickHouse 通用排除搜索算法在前置键列具有低（er）或高（er）基数的情况下，辅助键筛选粒度的工作原理。 作为这两种情况的示例，我们将假设： 查询 URL 值 = “W3” 的行。 我们的 hits 表的抽象版本，其中包含 UserID 和 URL 的简化值。 索引的相同复合主键 (UserID, URL)。这意味着行首先按 UserID 值排序。然后按 URL 对具有相同 UserID 值的行进行排序。 粒度大小为 2，即每个粒度包含两行。 我们在下图中用橙色标记了每个颗粒的最小键列值。 前置键列的基数较低 假设 UserID 具有低基数。在这种情况下，相同的 UserID 值很可能分布在多个表行和粒度上。对于具有相同 UserID 的索引标记，索引标记的 URL 值按升序排序（因为表行首先按 UserID 排序，然后按 URL 排序）。这能进行有效过滤，如下所示： 上图中我们的抽象样本数据的粒度选择过程有三种不同的场景： 由于标记索引0、1和2具有相同的UserID值，因此可以排除（最小）URL值小于W3并且直接后续索引标记的URL值也小于W3的索引标记0。请注意，此排除的前提是，确保了粒度 0 和下一个粒度1 完全由 U1的 UserID 值组成，因此 ClickHouse 可以推断粒度 0 中的最大 URL 值也小于 W3， 并排除该颗粒。 选择其URL 值小于（或等于）W3 并且其直接后续索引标记的 URL 值大于（或等于）W3的索引标记 1，因为这意味着粒度1 可能包含具有 URL值为W3 的行。 可以排除URL 值大于 W3的索引标记 2 和 3 ，因为主键索引的索引标记存储每个粒度的最小键列值，因此粒度 2 和 3 不可能包含 URL 值为 W3的行。 前置键列的基数的较高 当 UserID 具有高基数时，相同的 UserID 值不太可能分布在多个表行和粒度上。这意味着索引标记的 URL 值不是单调递增的： 正如我们在上图中看到的，所有显示的 URL 值小于 W3 的标记都被选中，用于将其关联的粒度行都流式传输到 ClickHouse 引擎。 这是因为虽然图中的所有索引标记都属于上述场景 1，但它们不满足上述排除的前提条件，即两个直接随后的索引标记都具有与当前标记相同的 UserID 值，因此不能被排除. 例如，考虑索引标记 0 ，其URL 值小于 W3 并且直接后续索引标记的 URL 值也存在小于 W3。这不能排除，因为两个紧随其后的索引标记 1 和 2没有与当前标记 0 相同的 UserID 值。 请注意，要求两个后续索引标记具有相同的 UserID 值。这确保了当前和下一个标记的粒度完全由 U1的 UserID 值组成。如果只有下一个标记具有相同的 UserID，则下一个标记的 URL 值可能源自具有不同 UserID 的表行 - 当您查看上图时确实是这种情况，即 W2 源自 U2，而不是UserID 为U1的行。 这最终会阻止 ClickHouse 对粒度 0 中的最大 URL 值做出推断。相反，它必须假设粒度 0 可能包含 URL 值为 W3 的行，并被迫选择标记 0。 同理，标记 1、2 和 3 也是如此。 结论 当查询对作为复合键的一部分但不是第一个键的列进行过滤，并且前置键列具有较低基数时，ClickHouse 使用通用排除搜索算法而不是二分搜索算法。 在我们的示例数据集中，两个键列（UserID、URL）具有相似的高基数，并且如上所述，当 URL 列的前一个键列具有较高或相似的基数时，通用排除搜索算法并不是十分有效. 注意跳数索引由于 UserID 和 URL 值具有同样高的基数，在使用复合主键 (UserID, URL)的表上的URL列上创建二级跳数索引，并不会对 URL 的查询过滤有太大的帮助。 例如，以下两个语句在我们表的 URL 列上创建并填充了一个minmax跳数索引： ALTER TABLE hits_UserID_URL ADD INDEX url_skipping_index URL TYPE minmax GRANULARITY 4; ALTER TABLE hits_UserID_URL MATERIALIZE INDEX url_skipping_index; ClickHouse 现在创建了一个附加索引，用于存储 - 每组 4 个连续粒度（注意上面ALTER TABLE语句中的GRANULARITY 4子句） - 的最小和最大 URL 值： 第一个索引项（上图中的“mark 0”）存储表的前 4 个粒度的行的最小和最大 URL 值。 第二个索引项（’mark 1’）存储表的后续 4 个粒度的行的最小和最大 URL 值，依此类推。 （ClickHouse 还为跳数索引创建了一个特殊的标记文件，用于定位与索引标记关联的粒度组。） 由于 UserID 和 URL 的基数同样高，所以当我们对 URL执行查询过滤时，这个二级跳数索引无法帮助排除被选中的粒度。 查询正在查找的特定 URL 值（如 “http: //public_search”）很可能介于索引为每组粒度存储的最小值和最大值之间，导致 ClickHouse 被迫选择粒度组（因为它们可能包含与查询匹配的行）。 需要使用多个主键索引因此，如果我们想要显着加快过滤具有特定 URL 的行的示例查询，那么我们需要使用针对该查询优化的主键索引。 此外，如果我们希望保持过滤具有特定 UserID 的行的示例查询的良好性能，那么我们需要使用多个主键索引。 以下是实现这一目标的方法。 用于创建附加主键索引的选项如果我们想显着加快我们的两个示例查询 - 一个过滤具有特定 UserID 的行和一个过滤具有特定 URL 的行 - 那么我们需要通过使用这三个选项之一来使用多个主索引： 使用不同的主键创建第二个表。 在我们现有的表上创建一个物化视图。 向我们现有的表添加投影。 所有的三个选项都会有效地将我们的样本数据复制到一个附加表中，以便重新组织表的主键索引和行排序顺序。 但是，这三个选项的不同之处在于附加表对于用户查询和插入语句处理的方便程度。 当创建了具有不同主键的第二个表后，必须将查询显式发送到最适合查询的表中，并且必须将新数据显式插入两个表中以保持表同步： 使用物化视图会隐式创建附加表，并且两个表之间的数据会自动保持同步： 投影是最方便的选项，因为除了自动保持隐式创建（和隐藏）附加表与同步数据更改之外，ClickHouse 将自动选择最有效的表版本进行查询： 在下文中，我们将通过实例来更详细地讨论创建和使用多个主索引的这三个选项。 选项 1：辅助表创建一个新的附加表，在主键中切换了键列的顺序（与原始表相比）： CREATE TABLE hits_URL_UserID ( `UserID` UInt32, `URL` String, `EventTime` DateTime ) ENGINE = MergeTree PRIMARY KEY (URL, UserID) ORDER BY (URL, UserID, EventTime) SETTINGS index_granularity = 8192, index_granularity_bytes = 0; 将原始表中的所有的 887 万行数据插入到附加表中： INSERT INTO hits_URL_UserID SELECT * from hits_UserID_URL; 响应如下所示： Ok. 0 rows in set. Elapsed: 2.898 sec. Processed 8.87 million rows, 838.84 MB (3.06 million rows/s., 289.46 MB/s.) 最后优化表： OPTIMIZE TABLE hits_URL_UserID FINAL; 因为我们切换了主键中列的顺序，插入的行现在以不同的字典顺序存储在磁盘上（与我们的原始表相比），因此该表的 1083 个粒度包含与之前不同的值： 这是生成的主键： 现在可以使用它来显着加快我们对 URL 列的示例查询过滤，以计算最常点击的 URL”http: //public_search”的前 10 个用户： SELECT UserID, count(UserID) AS Count FROM hits_URL_UserID WHERE URL = 'http://public_search' GROUP BY UserID ORDER BY Count DESC LIMIT 10; 响应如下： ┌─────UserID─┬─Count─┐ │ 2459550954 │ 3741 │ │ 1084649151 │ 2484 │ │ 723361875 │ 729 │ │ 3087145896 │ 695 │ │ 2754931092 │ 672 │ │ 1509037307 │ 582 │ │ 3085460200 │ 573 │ │ 2454360090 │ 556 │ │ 3884990840 │ 539 │ │ 765730816 │ 536 │ └────────────┴───────┘ 10 rows in set. Elapsed: 0.017 sec. Processed 319.49 thousand rows, 11.38 MB (18.41 million rows/s., 655.75 MB/s.) 现在， ClickHouse没有进行全表扫描，而是更有效地执行了该查询。 当使用原始表的主索引时，其中 UserID 是第一个，URL 是第二个键列，ClickHouse 对索引标记使用通用排除搜索来执行该查询。并且由于 UserID 和URL具有同样高的基数，使得该查询并不高效。 将 URL 作为主索引中的第一列，ClickHouse 现在对索引标记运行二分搜索。ClickHouse 服务器日志文件中的相应跟踪日志也验证了这一点： ...Executor): Key condition: (column 0 in ['http://public_search', 'http://public_search']) ...Executor): Running binary search on index range for part all_1_9_2 (1083 marks) ...Executor): Found (LEFT) boundary mark: 644 ...Executor): Found (RIGHT) boundary mark: 683 ...Executor): Found continuous range in 19 steps ...Executor): Selected 1/1 parts by partition key, 1 parts by primary key, 39/1083 marks by primary key, 39 marks to read from 1 ranges ...Executor): Reading approx. 319488 rows with 2 streams ClickHouse 仅选择了 39 个索引标记，而不是使用通用排除搜索时的 1076 个。 请注意，附加表经过优化，可加快我们对 URL 的示例查询过滤的执行速度。 与使用原始表时该查询的性能不佳同理，我们对 UserID 的示例查询过滤在新的附加表中不会有效地执行，因为 UserID 现在是该表主键索引中的第二个键列，因此 ClickHouse 将使用粒度选择的通用排除搜索，对于相似高基数的 UserID 和 URL列不是很有效。以下为详细信息。 对 UserID 的查询过滤现在性能很差 SELECT URL, count(URL) AS Count FROM hits_URL_UserID WHERE UserID = 749927693 GROUP BY URL ORDER BY Count DESC LIMIT 10; 响应如下 ┌─URL────────────────────────────┬─Count─┐ │ http://auto.ru/chatay-barana.. │ 170 │ │ http://auto.ru/chatay-id=371...│ 52 │ │ http://public_search │ 45 │ │ http://kovrik-medvedevushku-...│ 36 │ │ http://forumal │ 33 │ │ http://korablitz.ru/L_1OFFER...│ 14 │ │ http://auto.ru/chatay-id=371...│ 14 │ │ http://auto.ru/chatay-john-D...│ 13 │ │ http://auto.ru/chatay-john-D...│ 10 │ │ http://wot/html?page/23600_m...│ 9 │ └────────────────────────────────┴───────┘ 10 rows in set. Elapsed: 0.024 sec. Processed 8.02 million rows, 73.04 MB (340.26 million rows/s., 3.10 GB/s.) 服务器日志 ...Executor): Key condition: (column 1 in [749927693, 749927693]) ...Executor): Used generic exclusion search over index for part all_1_9_2 with 1453 steps ...Executor): Selected 1/1 parts by partition key, 1 parts by primary key, 980/1083 marks by primary key, 980 marks to read from 23 ranges ...Executor): Reading approx. 8028160 rows with 10 streams 我们现在有两张表。分别针对 UserID 的查询过滤和对 URL 的查询过滤进行了优化加速： 选项 2：物化视图在我们现有的表上创建一个物化视图。 CREATE MATERIALIZED VIEW mv_hits_URL_UserID ENGINE = MergeTree() PRIMARY KEY (URL, UserID) ORDER BY (URL, UserID, EventTime) POPULATE AS SELECT * FROM hits_UserID_URL; 响应如下所示： Ok. 0 rows in set. Elapsed: 2.935 sec. Processed 8.87 million rows, 838.84 MB (3.02 million rows/s., 285.84 MB/s.) 注意 我们在视图中的主键切换了主键列的顺序（与我们的原始表相比） 物化视图由隐式创建的表支持，该表的行顺序和主键索引基于给定的主键定义 隐式创建的表由SHOW TABLES查询列出，名称以.inner 开头 也可以首先显式地为物化视图创建依赖表，然后视图可以通过TO [db].[table] 子句定位该表。 我们使用POPULATE关键字来立即使用887 万行的源表hits_UserID_URL来填充隐式创建表 如果将新行插入到源表 hits_UserID_URL 中，那么这些行也会自动插入到隐式创建的表中 实际上，隐式创建的表与我们显式创建的辅助表具有相同的行顺序和主索引： ClickHouse 将隐式创建的表的列数据文件( .bin)、标记文件( .mrk2) 和主键索引文件(primary.idx) 存储在 ClickHouse 服务器数据目录的特殊文件夹中： 支持物化视图的隐式创建的表（以及它的主索引）现在可用于显着加快我们对 URL 列的示例查询过滤的执行速度： SELECT UserID, count(UserID) AS Count FROM mv_hits_URL_UserID WHERE URL = 'http://public_search' GROUP BY UserID ORDER BY Count DESC LIMIT 10; 响应如下： ┌─────UserID─┬─Count─┐ │ 2459550954 │ 3741 │ │ 1084649151 │ 2484 │ │ 723361875 │ 729 │ │ 3087145896 │ 695 │ │ 2754931092 │ 672 │ │ 1509037307 │ 582 │ │ 3085460200 │ 573 │ │ 2454360090 │ 556 │ │ 3884990840 │ 539 │ │ 765730816 │ 536 │ └────────────┴───────┘ 10 rows in set. Elapsed: 0.026 sec. Processed 335.87 thousand rows, 13.54 MB (12.91 million rows/s., 520.38 MB/s.) 因为实际上支持物化视图的隐式创建的表（以及它的主索引）与我们显式创建的辅助表相同，所以查询的执行方式与显式创建的表相同。 ClickHouse 服务器日志文件中的相应跟踪日志验证了 ClickHouse 正在对索引标记执行二分搜索： ...Executor): Key condition: (column 0 in ['http://public_search', 'http://public_search']) ...Executor): Running binary search on index range ... ... ...Executor): Selected 4/4 parts by partition key, 4 parts by primary key, 41/1083 marks by primary key, 41 marks to read from 4 ranges ...Executor): Reading approx. 335872 rows with 4 streams 选项 3：投影在我们现有的表上创建一个投影： ALTER TABLE hits_UserID_URL ADD PROJECTION prj_url_userid ( SELECT * ORDER BY (URL, UserID) ); 并实现投影： ALTER TABLE hits_UserID_URL MATERIALIZE PROJECTION prj_url_userid; 注意 投影创建一个隐藏表，其行顺序和主键索引基于投影给定的ORDER BY子句 SHOW TABLES查询不能列出隐藏的投影表 我们使用MATERIALIZE关键字，以便立即使用源表hits_UserID_URL中的所有 887 万行填充隐藏表 如果将新行插入到源表 hits_UserID_URL 中，那么这些行也会自动插入到隐藏表中 查询始终（在语法上）以源表 hits_UserID_URL 为目标，但如果隐藏表的行顺序和主索引允许更有效的查询执行，则将使用该隐藏表代替 实际上，隐式创建的隐藏表与我们显式创建的辅助表具有相同的行顺序和主键索引： ClickHouse 将隐藏表的列数据文件( .bin)、标记文件( .mrk2) 和主键索引文件(primary.idx) 存储在源表数据文件、标记文件和主索引文件旁边的特殊文件夹中（在下面的截图中标记为橙色）： 由投影创建的隐藏表（以及它的主键索引）现在可以（隐式地）用于显着加快我们在 URL 列上执行示例查询过滤的速度。请注意，查询在语法上以投影的源表为目标。 SELECT UserID, count(UserID) AS Count FROM hits_UserID_URL WHERE URL = 'http://public_search' GROUP BY UserID ORDER BY Count DESC LIMIT 10; 响应如下： ┌─────UserID─┬─Count─┐ │ 2459550954 │ 3741 │ │ 1084649151 │ 2484 │ │ 723361875 │ 729 │ │ 3087145896 │ 695 │ │ 2754931092 │ 672 │ │ 1509037307 │ 582 │ │ 3085460200 │ 573 │ │ 2454360090 │ 556 │ │ 3884990840 │ 539 │ │ 765730816 │ 536 │ └────────────┴───────┘ 10 rows in set. Elapsed: 0.029 sec. Processed 319.49 thousand rows, 1 1.38 MB (11.05 million rows/s., 393.58 MB/s.) 由于投影创建的隐藏表（以及它的主索引）实际上与我们显式创建的辅助表相同，所以查询的执行方式与显式创建的表相同。 ClickHouse 服务器日志文件中的相应跟踪日志证实了ClickHouse 正在对索引标记执行二分搜索： ...Executor): Key condition: (column 0 in ['http://public_search', 'http://public_search']) ...Executor): Running binary search on index range for part prj_url_userid (1083 marks) ...Executor): ... ...Executor): Choose complete Normal projection prj_url_userid ...Executor): projection required columns: URL, UserID ...Executor): Selected 1/1 parts by partition key, 1 parts by primary key, 39/1083 marks by primary key, 39 marks to read from 1 ranges ...Executor): Reading approx. 319488 rows with 2 streams 总结具有复合主键 (UserID, URL)的表的主键索引对于加快UserID 的查询过滤非常有用。但是，尽管 URL 列是复合主键的一部分，但该索引并没有为加快 URL 的查询过滤提供重要帮助。 反之亦然：具有复合主键 (URL, UserID) 的表的主键索引能加快对 URL 的查询过滤，但对 UserID的查询过滤没有提供太多帮助。 由于主键列 UserID 和 URL 具有相似的高基数，对第二个键列进行过滤的查询不会从索引中的第二个键列中获得太多帮助。 因此，从主索引中删除第二个键列（从而减少索引的内存消耗）并改用多个主索引是有意义的。 但是，如果复合主键中的键列在基数上有很大差异，则查询按基数升序排列主键列是有益的。 键列之间的基数差异越大，这些列在键中的顺序就越重要。我们将在下一节中证明这一点。 因此，从主键索引中删除第二个键列（从而减少索引的内存消耗）并改用多个主键索引是有意义的。 但是，如果复合主键中的键列在基数上有很大差异，则按基数升序排列的主键列对查询是有帮助的。 键列之间的基数差异越大，这些列在键中的顺序就越重要。 我们将在下一节中说明这一点。 有效地对键列进行排序在复合主键中，键列的顺序会明显影响以下两点： 查询中辅助键列的过滤效率，以及 表的数据文件的压缩率。 为了证明这一点，我们将使用我们的网络流量示例数据集的一个版本， 其中每行包含三列，代表互联网“用户”（UserID列）对 URL（URL列）的访问是否被标记为机器人流量（IsRobot列）。 我们将使用包含所有上述三个列的复合主键，可用于加速典型的 Web 分析查询 到特定 URL 的流量有多少（百分比）来自机器人 我们判断特定用户是否为机器人的准确程度（来自该用户的流量有多少百分比是否被假定为机器人流量） 我们使用此查询来计算要用作复合主键中的键列的三列的基数（请注意，我们正在使用URL 表函数来临时查询 TSV 数据，而无需创建本地表） . 在clickhouse client运行此查询： SELECT formatReadableQuantity(uniq(URL)) AS cardinality_URL, formatReadableQuantity(uniq(UserID)) AS cardinality_UserID, formatReadableQuantity(uniq(IsRobot)) AS cardinality_IsRobot FROM ( SELECT c11::UInt64 AS UserID, c15::String AS URL, c20::UInt8 AS IsRobot FROM url('https://datasets.clickhouse.com/hits/tsv/hits_v1.tsv.xz') WHERE URL != '' ) 响应如下： ┌─cardinality_URL─┬─cardinality_UserID─┬─cardinality_IsRobot─┐ │ 2.39 million │ 119.08 thousand │ 4.00 │ └─────────────────┴────────────────────┴─────────────────────┘ 1 row in set. Elapsed: 118.334 sec. Processed 8.87 million rows, 15.88 GB (74.99 thousand rows/s., 134.21 MB/s.) 我们可以看到基数之间存在很大差异，尤其是URL和IsRobot列之间。因此复合主键中列的顺序，对于有效加快对该列的查询过滤和实现最佳表的列数据文件压缩比都十分重要。 为了说明这一点，流量分析数据创建了两个表版本： 具有复合主键(URL, UserID, IsRobot)的表hits_URL_UserID_IsRobot，我们按基数降序对键列进行排序 具有复合主键(IsRobot, UserID, URL)的表hits_IsRobot_UserID_URL，我们按基数升序对键列进行排序 使用复合主键(URL, UserID, IsRobot)创建表hits_URL_UserID_IsRobot： CREATE TABLE hits_URL_UserID_IsRobot ( `UserID` UInt32, `URL` String, `IsRobot` UInt8 ) ENGINE = MergeTree PRIMARY KEY (URL, UserID, IsRobot); 并用 887 万行填充它： INSERT INTO hits_URL_UserID_IsRobot SELECT intHash32(c11::UInt64) AS UserID, c15 AS URL, c20 AS IsRobot FROM url('https://datasets.clickhouse.com/hits/tsv/hits_v1.tsv.xz') WHERE URL != ''; 响应如下： 0 rows in set. Elapsed: 104.729 sec. Processed 8.87 million rows, 15.88 GB (84.73 thousand rows/s., 151.64 MB/s.) 接下来，使用复合主键(IsRobot, UserID, URL)创建表hits_IsRobot_UserID_URL： CREATE TABLE hits_IsRobot_UserID_URL ( `UserID` UInt32, `URL` String, `IsRobot` UInt8 ) ENGINE = MergeTree PRIMARY KEY (IsRobot, UserID, URL); 并用我们填充上一个表的相同的 887 万行来填充它： INSERT INTO hits_IsRobot_UserID_URL SELECT intHash32(c11::UInt64) AS UserID, c15 AS URL, c20 AS IsRobot FROM url('https://datasets.clickhouse.com/hits/tsv/hits_v1.tsv.xz') WHERE URL != ''; 响应如下： 0 rows in set. Elapsed: 95.959 sec. Processed 8.87 million rows, 15.88 GB (92.48 thousand rows/s., 165.50 MB/s.) 对辅助键列的有效过滤当查询过滤在作为复合键的一部分并且是第一个键列的至少一列上时，ClickHouse 将在键列的索引标记上运行二分搜索算法。 当查询（仅）对作为复合键的一部分但不是第一个键列的列进行过滤时，ClickHouse 将在键列的索引标记上使用通用排除搜索算法。 对于第二种情况，复合主键中键列的排序对于通用排除搜索算法的高效性非常重要。 这是一个过滤UserID列的查询，其中表(URL, UserID, IsRobot)按基数降序对键列进行排序： SELECT count(*) FROM hits_URL_UserID_IsRobot WHERE UserID = 112304 响应为： ┌─count()─┐ │ 73 │ └─────────┘ 1 row in set. Elapsed: 0.026 sec. Processed 7.92 million rows, 31.67 MB (306.90 million rows/s., 1.23 GB/s.) 这是对表(IsRobot, UserID, URL)执行的相同查询，其中表按基数升序对键列进行排序： SELECT count(*) FROM hits_IsRobot_UserID_URL WHERE UserID = 112304 响应是： ┌─count()─┐ │ 73 │ └─────────┘ 1 row in set. Elapsed: 0.003 sec. Processed 20.32 thousand rows, 81.28 KB (6.61 million rows/s., 26.44 MB/s.) 我们可以看到，在我们按基数以升序对键列进行排序的表上，查询执行明显更有效、更快。 原因是通用排除搜索算法最有效，当通过辅助键列选择粒度时，前导键列具有较低的基数。我们在本指南的前一节中详细说明了这一点。 数据文件的最佳压缩率此查询比较我们在上面创建的两个表之间的UserID列的压缩率： SELECT table AS Table, name AS Column, formatReadableSize(data_uncompressed_bytes) AS Uncompressed, formatReadableSize(data_compressed_bytes) AS Compressed, round(data_uncompressed_bytes / data_compressed_bytes, 0) AS Ratio FROM system.columns WHERE (table = 'hits_URL_UserID_IsRobot' OR table = 'hits_IsRobot_UserID_URL') AND (name = 'UserID') ORDER BY Ratio ASC 响应如下： ┌─Table───────────────────┬─Column─┬─Uncompressed─┬─Compressed─┬─Ratio─┐ │ hits_URL_UserID_IsRobot │ UserID │ 33.83 MiB │ 11.24 MiB │ 3 │ │ hits_IsRobot_UserID_URL │ UserID │ 33.83 MiB │ 877.47 KiB │ 39 │ └─────────────────────────┴────────┴──────────────┴────────────┴───────┘ 2 rows in set. Elapsed: 0.006 sec. 我们可以看到，对于我们按基数以升序对键列(IsRobot, UserID, URL)进行排序的表，UserID列的压缩率明显更高。 尽管在两个表中存储了完全相同的数据（我们在两个表中插入了相同的 887 万行），但复合主键中键列的顺序对表的列数据文件中的压缩数据占用多少磁盘空间有很大影响： 在具有复合主键(URL, UserID, IsRobot)的表hits_URL_UserID_IsRobot中，我们按基数降序排列键列，UserID.bin数据文件占用11.24 MiB的磁盘空间 在具有复合主键(IsRobot, UserID, URL)的表hits_IsRobot_UserID_URL中，我们按基数升序对键列进行排序，UserID.bin数据文件仅占用877.47 KiB磁盘空间 磁盘上的表列数据具有良好的压缩比不仅可以节省磁盘空间，而且还可以使需要从该列读取数据的查询（尤其是分析查询）更快，因为从磁盘到主存（操作系统的文件缓存）移动列的数据所需的 i/o 更少。 下面我们将说明为什么主键按基数升序排列对表列的压缩率有好处。 下图描绘了主键在磁盘上的行顺序，其中键列按基数升序排列： 我们说明了表的行数据按主键列排序存储在磁盘上。 在上图中，表的行（它们在磁盘上的列值）首先按cl值排序，具有相同cl值的行按其ch值排序。并且由于第一个键列cl的基数较低，很可能存在具有相同cl值的行。因此，ch值也可能是有序的（局部 - 对于具有相同cl值的行）。 如果在一列中，相似的数据彼此靠近放置，例如通过排序，那么该数据将被更好地进行压缩。一般来说，压缩算法受益于数据的长度（数据越多，压缩效果越好）和局部性（数据越相似，压缩比越好）。 与上图相反，下图描绘了磁盘上行顺序按主键基数降序排列： 现在表的行首先按它们的ch值排序，具有相同ch值的行按它们的cl值排序。但是因为第一个键列ch的基数很高，所以不可能有相同ch值的行。并且因此也不太可能对cl值进行排序（局部 - 对于具有相同ch值的行）。 因此，这些cl值很可能是随机顺序的，因此分别具有较差的局部性和压缩比。 总结对于提升查询中的辅助键列的有效过滤和表的列数据文件的压缩率，将主键中的列按其基数升序排列是有帮助的。 有效识别单行虽然通常它不是ClickHouse 的最佳用例，但有时在 构建ClickHouse 之上的应用程序需要识别 ClickHouse 表的单行。 一个直观的解决方案是使用每行具有唯一值的UUID列，并将该列用作主键列以快速检索行。 为了最快的检索，UUID 列需要是第一个键列。 我们讨论了因为ClickHouse 表的行数据存储在按主键列排序的磁盘上，因此在主键或复合主键中具有非常高的基数的列（如 UUID 列）在具有较低基数的列之外是不利于表列的压缩比。 最快检索和最佳数据压缩之间的折衷方案是使用复合主键，其中 UUID 是最后一个键列，位于用于确保某些表列的良好压缩比的低基数键列之后。 一个具体的例子一个具体的例子是Alexey Milovidov 开发并提到的文本粘贴服务https://pastila.nl。 每次更改文本区域时，数据都会自动保存到 ClickHouse 表行（每次更改一行）。 识别和检索（特定版本）粘贴内容的一种方法是使用内容的hash作为包含该内容的表行的 UUID。 下图说明 内容更改时行的插入顺序（例如，由于在文本区域中输入文本）和 使用PRIMARY KEY (hash)时插入的行数据在磁盘上的顺序： 因为该hash列被用作主键列 可以非常快速地检索特定的行，但是 表的行（它们的列数据）按（唯一和随机）哈希值升序排列存储在磁盘上。因此，内容列的值也以随机顺序存储，没有数据局部性，导致内容列数据文件的压缩率次优。 为了显着提高内容列的压缩率，同时仍然实现对特定行的快速检索，pasila.nl 使用两个哈希值（和一个复合主键）来识别特定行： 如上所述，内容的哈希值对于不同的数据是不同的，以及 一个局部敏感的hash（指纹），不会因数据的微小变化而改变。 下图显示 内容更改时行的插入顺序（例如，由于在文本区域中输入文本）和 使用复合主键PRIMARY KEY (fingerprint, hash)时插入行数据在磁盘上的顺序： 现在磁盘上的行首先按fingerprint排序，对于具有相同指纹值的行，它们的hash值决定了最终的顺序。 因为只有微小变化的数据会获得相同的指纹值，所以现在相似的数据存储在磁盘上的内容列中彼此靠近。这对内容列的压缩率非常有利，因为压缩算法通常受益于数据局部性（数据越相似，压缩率越好）。 折衷方案是检索特定行需要两个字段 (fingerprint和hash)，以便最佳地利用产生的复合主索引PRIMARY KEY (fingerprint, hash)。","categories":[{"name":"ClickHouse","slug":"ClickHouse","permalink":"https://onehr7.github.io/categories/ClickHouse/"}],"tags":[]},{"title":"Kafka三节点集群搭建","slug":"Kafka三节点集群搭建","date":"2022-01-10T11:50:15.000Z","updated":"2022-09-10T12:38:41.349Z","comments":true,"path":"2022/01/10/Kafka三节点集群搭建/","link":"","permalink":"https://onehr7.github.io/2022/01/10/Kafka%E4%B8%89%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/","excerpt":"一 整体步骤 hosts配置 安装配置Zookeeper Kafka集群搭建","text":"一 整体步骤 hosts配置 安装配置Zookeeper Kafka集群搭建 二 配置Hosts 修改hosts文件 sudo vi /etc/hosts # 配置如下 127.0.0.1 localhost 192.168.0.100 master 192.168.0.101 slave1 192.168.0.102 slave2 三 安装配置Zookeeper 下载解压 # 使用wget或本地下载后传到服务器 cd /home/ sudo mkdir zookeeper cd /home/zookeeper sudo wget https://dlcdn.apache.org/zookeeper/zookeeper-3.5.9/apache-zookeeper-3.5.9-bin.tar.gz sudo tar -zxvf apache-zookeeper-3.5.9-bin.tar.gz 配置环境变量 # 修改三台主机 # sudo vi /etc/profile # 添加环境变量 export ZOOKEEPER_HOME=/home/zookeeper/apache-zookeeper-3.5.9-bin export PATH=$ZOOKEEPER_HOME/bin:$PATH source /etc/profile 创建目录 cd apache-zookeeper-3.5.9-bin sudo mkdir data sudo mkdir logs 修改配置 cd conf sudo cp zoo_sample.cfg zoo.cfg sudo vi zoo.cfg tickTime=2000 initLimit=10 syncLimit=5 dataDir=/home/zookeeper/apache-zookeeper-3.5.9-bin/data dataLogDir=/home/zookeeper/apache-zookeeper-3.5.9-bin/logs clientPort=2181 # 如果为当前主机，则修改为0.0.0.0 server.1=master:2287:3387 server.2=slave1:2287:3387 server.3=slave2:2287:3387 创建myid文件 在各服务器节点(master、slave1、slave2)的 dataDir 目录下创建名为 myid 的文件，在文件第一行写上对应的 Server id master: echo \"1\" > myid slave1: echo \"2\" > myid slave2: echo \"3\" > myid 启动测试 启动顺序决定leadert,follower # 分别在三台主机上 cd /home/zookeeper/apache-zookeeper-3.5.9-bin/bin/ zkServer.sh start # 集群验证 # 查看状态(需全部节点启动) zkServer.sh status 基本命令 # 停止 zkServer.sh stop 四 KafKa 集群搭建 下载解压 注意选择版本时，选择Binary downloads,不要选择Source download！！！否则启动时会提示Could not find or load main class kafka.Kafka，此时需要编译后才可以使用 。 cd /home mkdir Kafka cd Kafka mkdir data sudo wget https://archive.apache.org/dist/kafka/3.0.0/kafka_2.12-3.0.0.tgz tar -xzf kafka_2.12-3.0.0.tgz 修改配置 cd kafka_2.12-3.0.0/config vi server.properties # 节点1 # 群中每个节点的唯一标识 broker.id=0 # 监听地址 listeners=PLAINTEXT://master:9092 # 数据的存储位置 log.dirs=/home/Kafka/data # Zookeeper连接地址 zookeeper.connect=master:2181,slave1:2181,slave2:2181 # 节点2 broker.id=1 listeners=PLAINTEXT://slave1:9092 log.dirs=/home/Kafka/data zookeeper.connect=master:2181,slave1:2181,slave2:2181 # 节点3 broker.id=2 listeners=PLAINTEXT://slave2:9092 log.dirs=/home/Kafka/data zookeeper.connect=master:2181,slave1:2181,slave2:2181 启动 # 三节点分别运行启动 cd /home/Kafka/kafka_2.12-3.0.0 bin/kafka-server-start.sh -daemon config/server.properties 测试 bin/kafka-topics.sh --create --bootstrap-server master:9092 --replication-factor 1 --partitions 1 --topic test bin/kafka-topics.sh --list --bootstrap-server master:9092 bin/kafka-topics.sh --describe --bootstrap-server master:9092 --topic test","categories":[{"name":"Kafka","slug":"Kafka","permalink":"https://onehr7.github.io/categories/Kafka/"}],"tags":[]},{"title":"当Clickhouse Distributed遇到ReplacingMergeTree","slug":"当Clickhouse Distributed遇到ReplacingMergeTree","date":"2021-09-07T14:48:02.000Z","updated":"2021-09-21T13:33:16.244Z","comments":true,"path":"2021/09/07/当Clickhouse Distributed遇到ReplacingMergeTree/","link":"","permalink":"https://onehr7.github.io/2021/09/07/%E5%BD%93Clickhouse%20Distributed%E9%81%87%E5%88%B0ReplacingMergeTree/","excerpt":"问题描述​ 由于业务限制，数据库中存在大量重复数据，故采用了ReplacingMergeTree表引擎，但后台始终没有进行数据合并。","text":"问题描述​ 由于业务限制，数据库中存在大量重复数据，故采用了ReplacingMergeTree表引擎，但后台始终没有进行数据合并。 建表语句 CREATE TABLE xxxx.xxxx ON CLUSTER xxx ( user_id String, name String, ) ENGINE = ReplacingMergeTree() ORDER BY (user_id); CREATE TABLE xxxx.xxxx ON CLUSTER xxx as xxxx.xxxx ENGINE = Distributed('xxxx', 'xxxx', xxxx, rand()); 查询数据是否有重复 SELECT COUNT() FROM xxxx.xxxx 41905623 SELECT COUNT(x) FROM (SELECT x FROM xxxx.xxxx GROUP BY [oder_key]) 41705616 手动执行数据合并，也没有去除重复数据 OPTIMIZE TABLE ~ ON CLUSTER ~ FINAL SELECT COUNT() FROM xxxx.xxxx 41905623 思考​ 分布式表存储数据采用分片存储，如6条数据存3个节点，则每个节点存储2条数据。当发生数据合并时，可能只合并当前节点的数据。最终也在这https://stackoverflow.com/questions/62616949/deduplication-in-distributed-clickhouse-table，验证了这一猜想。 解决​ 创建分布式表时，不使用rand()进行随机分布，使用user_id进行分片，使相同user_id的数据在写入时落在相同的节点。 CREATE TABLE xxxx.xxxx ON CLUSTER xxx as xxxx.xxxx ENGINE = Distributed('xxxx', 'xxxx', xxxx, user_id);","categories":[{"name":"ClickHouse","slug":"ClickHouse","permalink":"https://onehr7.github.io/categories/ClickHouse/"}],"tags":[{"name":"ReplacingMergeTree","slug":"ReplacingMergeTree","permalink":"https://onehr7.github.io/tags/ReplacingMergeTree/"}]},{"title":"解决Python3 urllib3 urllib3.exceptions.maxretryerror httpsconnectionpool(host=‘xxxxx‘, port=443)","slug":"解决Python3 urllib3 urllib3.exceptions.maxretryerror httpsconnectionpool(host=‘xxxxx‘, port=443)","date":"2021-06-21T12:11:35.000Z","updated":"2022-09-10T12:30:34.592Z","comments":true,"path":"2021/06/21/解决Python3 urllib3 urllib3.exceptions.maxretryerror httpsconnectionpool(host=‘xxxxx‘, port=443)/","link":"","permalink":"https://onehr7.github.io/2021/06/21/%E8%A7%A3%E5%86%B3Python3%20urllib3%20urllib3.exceptions.maxretryerror%20httpsconnectionpool(host=%E2%80%98xxxxx%E2%80%98,%20port=443)/","excerpt":"报错原因在使用代理进行请求时，代理只通过HTTP请求，此时请求进行HTTPS验证时验证失败。","text":"报错原因在使用代理进行请求时，代理只通过HTTP请求，此时请求进行HTTPS验证时验证失败。 两种解决方案 在1.25版本之前，请求时不会进行HTTPS验证。故可降低urllib3版本。 1.25 (2019-04-22) Require and validate certificates by default when using HTTPS (Pull #1507) pip install -U \"urllib3","categories":[{"name":"Python","slug":"Python","permalink":"https://onehr7.github.io/categories/Python/"}],"tags":[{"name":"ssl","slug":"ssl","permalink":"https://onehr7.github.io/tags/ssl/"}]},{"title":"Pyinstall打包ssl验证错误","slug":"Pyinstall打包ssl验证错误","date":"2021-05-28T15:17:35.000Z","updated":"2021-06-07T14:50:56.266Z","comments":true,"path":"2021/05/28/Pyinstall打包ssl验证错误/","link":"","permalink":"https://onehr7.github.io/2021/05/28/Pyinstall%E6%89%93%E5%8C%85ssl%E9%AA%8C%E8%AF%81%E9%94%99%E8%AF%AF/","excerpt":"使用Google api，程序能正常运行，但使用PyInstaller打包后出现ssl验证错误 Error: Exception in ‘grpc._cython.cygrpc.ssl_roots_override_callback’ ignored assertion failed: pem_root_certs != nullptr","text":"使用Google api，程序能正常运行，但使用PyInstaller打包后出现ssl验证错误 Error: Exception in ‘grpc._cython.cygrpc.ssl_roots_override_callback’ ignored assertion failed: pem_root_certs != nullptr 解决办法 找到Python安装路径下的\\Lib\\site-packages\\grpc_cython_credentials\\roots.pem, 并拷贝到打包后的exe文件目录下。 参考链接 https://github.com/grpc/grpc/issues/9223#issuecomment-412054216","categories":[{"name":"Python","slug":"Python","permalink":"https://onehr7.github.io/categories/Python/"}],"tags":[{"name":"PyInstaller","slug":"PyInstaller","permalink":"https://onehr7.github.io/tags/PyInstaller/"}]},{"title":"CentOS7安装三节点Hadoop集群","slug":"CentOS7安装三节点Hadoop集群","date":"2021-03-22T15:14:35.000Z","updated":"2021-06-07T14:49:21.256Z","comments":true,"path":"2021/03/22/CentOS7安装三节点Hadoop集群/","link":"","permalink":"https://onehr7.github.io/2021/03/22/CentOS7%E5%AE%89%E8%A3%85%E4%B8%89%E8%8A%82%E7%82%B9Hadoop%E9%9B%86%E7%BE%A4/","excerpt":"一 服务器配置 关闭防火墙 # 查看状态 firewall-cmd --state # 停止防火墙 systemctl stop firewalld.service # 禁止开机自启动 systemctl disable firewalld.service 关闭selinux vi /etc/sysconfig/selinux SELINUX=disabled","text":"一 服务器配置 关闭防火墙 # 查看状态 firewall-cmd --state # 停止防火墙 systemctl stop firewalld.service # 禁止开机自启动 systemctl disable firewalld.service 关闭selinux vi /etc/sysconfig/selinux SELINUX=disabled 二 网络配置 找到待配置网卡 cd /etc/sysconfig/network-scripts/ ls # 这里选择ifcfg-enp3s0 vi ifcfg-enp3s0 修改下列配置 BOOTPROTO=static ONBOOT=yes IPADDR=192.168.0.200 GATEWAY=192.168.0.1 DNS1=8.8.8.8 网络测试 service network restart # 局域网测试 ping 192.168.0.229 # 外网测试 ping www.baidu.com 三 安装Java 创建安装目录 cd /home/whr mkdir java cd java 安装wget yum -y install wget 下载解压 使用wget下载或通过官网下载后，使用WinSCP传到 /home/whr/java 目录下 cd /home/whr/java tar -zxvf jdk-8u281-linux-x64.tar.gz 设置环境变量 vi /etc/profile # 末尾添加 export JAVA_HOME=/home/whr/java/jdk1.8.0_281 export JRE_HOME=$&#123;JAVA_HOME&#125;/jre export CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/lib export PATH=$&#123;JAVA_HOME&#125;/bin:$PATH # 激活环境变量 source /etc/profile 添加软链接 ln -s /home/whr/java/jdk1.8.0_281/bin/java /usr/bin/java 安装完成 java -version 四 配置hosts 节点规划 IP NodeType Name 192.168.0.200 DataNode slave1 192.168.0.201 DataNode slave2 192.168.0.202 NameNode / DataNode master hosts 配置 vi /etc/hosts # 配置如下 127.0.0.1 localhost 192.168.0.200 slave1 192.168.0.201 slave2 192.168.0.202 master 五 配置SSH（主节点） 修改配置文件 vi /etc/ssh/sshd_config AuthorizedKeysFile .ssh/authorized_keys PubkeyAuthentication yes 生成秘钥 ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa 分发公钥 ssh-copy-id -i ~/.ssh/id_dsa.pub master ssh-copy-id -i ~/.ssh/id_dsa.pub slave1 ssh-copy-id -i ~/.ssh/id_dsa.pub slave2 # 验证 ssh master ssh slave1 ssh slave2 六 安装Hadoop（主节点） 下载 cd /home/whr mkdir hadoop cd hadoop wget https://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/hadoop-3.2.1/hadoop-3.2.1.tar.gz # 或本地下载使用WinSCP传送 安装 tar zxvf hadoop-3.2.1.tar.gz # 创建软链接 ln -s /home/whr/hadoop/hadoop-3.2.1 /usr/local/hadoop 配置Hadoop环境变量 vi /etc/profile # 末尾添加 export HADOOP_HOME=/home/whr/hadoop/hadoop-3.2.1 export PATH=$&#123;HADOOP_HOME&#125;/bin:$PATH source /etc/profile 修改配置文件 cd /usr/local/hadoop/etc/hadoop 配置hadoop-env.sh vi hadoop-env.sh export JAVA_HOME=/home/whr/java/jdk1.8.0_281 配置core-site.xml vi core-site.xml hadoop.tmp.dir /home/whr/hadoop/tmp Abase for other temporary directories. fs.default.name hdfs://master:9000 配置hdfs-site.xml vi hdfs-site.xml dfs.namenode.name.dir /home/whr/hadoop/dfs/name dfs.datanode.data.dir /home/whr/hadoop/dfs/data 配置yarn-site.xml vi yarn-site.xml yarn.nodemanager.aux-services mapreduce_shuffle yarn.nodemanager.aux-services.mapreduce_shuffle.class org.apache.hadoop.mapred.ShuffleHandler yarn.resourcemanager.hostname master 配置mapred-site.xml vi mapred-site.xml mapred.job.tracker master:49001 mapred.local.dir /home/whr/hadoop/var mapreduce.framework.name yarn 配置workers vi workers master slave1 slave2 修改hdfs启动和停止脚本 cd /usr/local/hadoop/sbin vi start-dfs.sh vi stop-dfs.sh # 在最前面加如下内容 HDFS_DATANODE_USER=root HADOOP_SECURE_DN_USER=root HDFS_NAMENODE_USER=root HDFS_SECONDARYNAMENODE_USER=root 修改yarn启动和停止脚本 cd /usr/local/hadoop/sbin vi start-yarn.sh vi stop-yarn.sh # 在文件前添加如下内容 YARN_RESOURCEMANAGER_USER=root HADOOP_SECURE_DN_USER=root YARN_NODEMANAGER_USER=root 从节点配置Hadoop # 将配置好的Hadoop复制到从节点 scp -r /home/whr/hadoop/hadoop-3.2.1 root@192.168.0.201:/home/whr/hadoop/ # 设置软链接 ssh slave1 ln -s /home/whr/hadoop/hadoop-3.2.1 /usr/local/hadoop exit ssh slave2 ln -s /home/whr/hadoop/hadoop-3.2.1 /usr/local/hadoop exit 七 启动测试 格式化namenode hdfs namenode -format # 重新格式化需要删除tmp和dfs文件夹 启动hdfs cd /usr/local/hadoop/sbin bash start-all.sh 启动yarn bash start-all.sh 验证 jps 4800 NodeManager 4002 NameNode 4387 SecondaryNameNode 4666 ResourceManager 13355 Jps 4126 DataNode 客户端访问 http://192.168.0.202:9870/ http://192.168.0.202:8088/","categories":[{"name":"大数据","slug":"大数据","permalink":"https://onehr7.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"tags":[]},{"title":"Pyinstaller打包配置文件","slug":"Pyinstaller 打包配置文件夹","date":"2021-03-05T09:12:38.000Z","updated":"2021-03-07T09:54:41.624Z","comments":true,"path":"2021/03/05/Pyinstaller 打包配置文件夹/","link":"","permalink":"https://onehr7.github.io/2021/03/05/Pyinstaller%20%E6%89%93%E5%8C%85%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E5%A4%B9/","excerpt":"Pyinstaller 打包配置文件夹","text":"Pyinstaller 打包配置文件夹 生成资源文件目录访问路径 import os import sys def resource_path(relative_path): if getattr(sys, 'frozen', False): base_path = sys._MEIPASS else: base_path = os.path.abspath(\".\") return os.path.join(base_path, relative_path) 修改需要读取路径的文件或文件夹 resource_path(os.path.join(\"config\", \"data.txt\")) 打包py文件生成.spec文件 pyinstaller -F QueryGui.py 修改.spec文件中datas项，添加配置文件目录和待生成的文件夹名 a = Analysis([''], pathex=[''], binaries=[], datas=[('config', 'config')], 删除build和dist文件夹，重新生成打包文件 pyinstaller -F QueryGui.spec","categories":[{"name":"python","slug":"python","permalink":"https://onehr7.github.io/categories/python/"}],"tags":[]},{"title":"Selenium获取请求信息","slug":"Selenium获取请求信息","date":"2021-01-26T14:37:00.000Z","updated":"2021-01-26T14:37:31.284Z","comments":true,"path":"2021/01/26/Selenium获取请求信息/","link":"","permalink":"https://onehr7.github.io/2021/01/26/Selenium%E8%8E%B7%E5%8F%96%E8%AF%B7%E6%B1%82%E4%BF%A1%E6%81%AF/","excerpt":"前言​ 在获取facebook analytics数据时，抓取到的请求需要携带token，且具有时效性。","text":"前言​ 在获取facebook analytics数据时，抓取到的请求需要携带token，且具有时效性。 解决办法 JS逆向分析token生成过程及逻辑（难度较大，尝试无果后放弃） 使用selenium模拟请求，将过程交给浏览器，只需要获取结果 实现代码from time import sleep from selenium import webdriver option = webdriver.ChromeOptions() # 使用本地cookie, 运行时需关闭已打开的浏览器 option.add_argument(r'--user-data-dir=C:\\...\\User Data') option.add_argument('--profile-directory=Default') browser = webdriver.Chrome(options=option) browser.get(\"https://www.facebook.com/analytics/\") sleep(10) # 获取selenium执行了那些请求的关键 test = browser.execute_script(\"var performance = window.performance || window.mozPerformance || window.msPerformance || window.webkitPerformance || &amp;#123;&amp;#125;; var network = performance.getEntries() || &amp;#123;&amp;#125;; return network;\") access_token = \"\" for item in test: if \"access_token\" in item['name']: access_token = item['name'].split(\"=\")[-1] print(access_token) browser.quit()","categories":[{"name":"爬虫","slug":"爬虫","permalink":"https://onehr7.github.io/categories/%E7%88%AC%E8%99%AB/"}],"tags":[{"name":"selenium","slug":"selenium","permalink":"https://onehr7.github.io/tags/selenium/"}]},{"title":"并查集及Python实现","slug":"并查集及Python实现","date":"2021-01-18T12:22:00.000Z","updated":"2021-01-18T14:54:04.449Z","comments":true,"path":"2021/01/18/并查集及Python实现/","link":"","permalink":"https://onehr7.github.io/2021/01/18/%E5%B9%B6%E6%9F%A5%E9%9B%86%E5%8F%8APython%E5%AE%9E%E7%8E%B0/","excerpt":"并查集：在计算机科学中，并查集是一种树型的数据结构，用于处理一些不交集（Disjoint Sets）的合并及查询问题。 —wiki","text":"并查集：在计算机科学中，并查集是一种树型的数据结构，用于处理一些不交集（Disjoint Sets）的合并及查询问题。 —wiki 定义​ 并查集，顾名思义，包含了合并和查询操作，用于解决动态连通性问题。 实现过程# 主体框架 class UnionFind(object): # 初始化 def __init__(self): pass # 查询根节点 def find(self): pass # 合并节点 def union(self): pass # 判断两个节点是否连通 def is_same_set(self): pass 初始化 将所有节点的父节点设为None def __init__(self, M): self.father_dict = &amp;#123;&amp;#125; # 记录集合的数量，一般为返回值 self.nums_set = 0 for i in range(len(M)): if i not in self.father_dict: self.father_dict[i] = None # 集合的数量+1 self.nums_set += 1 查询 def find(self, x): root = x while self.father_dict[root] != None: root = self.father_dict[root] # 路径压缩 while x != root: cur_father = self.father_dict[x] self.father_dict[x] = root x = cur_father return root 合并 def union(self, a, b): a_root, b_root = self.find(a), self.find(b) # 任意指定一个节点为父节点 if a_root != b_root: self.father_dict[a_root] = b_root self.nums_set -= 1 判断是否在同一集合 def is_same_set(self, a, b): return self.find(a) == self.find(b)","categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://onehr7.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"并查集","slug":"并查集","permalink":"https://onehr7.github.io/tags/%E5%B9%B6%E6%9F%A5%E9%9B%86/"}]},{"title":"pandas浅析","slug":"pandas总结","date":"2021-01-07T05:18:50.000Z","updated":"2021-01-17T08:27:16.482Z","comments":true,"path":"2021/01/07/pandas总结/","link":"","permalink":"https://onehr7.github.io/2021/01/07/pandas%E6%80%BB%E7%BB%93/","excerpt":"创建DataFrame​","text":"创建DataFrame​ import pandas as pd 读取csv文件并转为DataFrame csv_data = pd.read_csv(\"test_data.csv\", encoding = \"ISO-8859-1\") 字典转为DataFrame d = &#123;'col1': [1, 2], 'col2': [3, 4]&#125; df = pd.DataFrame(data=d) col1 col2 0 1 3 1 2 4 双层列表转为DataFrame data = [['tom', 10], ['nick', 15], ['juli', 14]] # Create the pandas DataFrame df = pd.DataFrame(data, columns = ['Name', 'Age']) Name Age 0 tom 10 1 nick 15 2 juli 14 列表字典转DataFrame data = [&#123;'a': 1, 'b': 2, 'c':3&#125;, &#123;'a':10, 'b': 20, 'c': 30&#125;] # Creates DataFrame. df = pd.DataFrame(data) a b c 0 1 2 3 1 10 20 30 指定index df = pd.DataFrame(data, index =['rank1', 'rank2', 'rank3', 'rank4']) 修改DataFrame值 修改一列的值 df[\"data\"] = df[\"data\"].map(lambda x: 0) 修改多列的值 for index, row in df_res.iterrows(): df_res.at[index, 'data1'] = 0 df_res.at[index, 'data2'] = 0 类型转换 整体转为str df = df.astype(str) 整体转为int df = df.astype(int)","categories":[{"name":"python","slug":"python","permalink":"https://onehr7.github.io/categories/python/"}],"tags":[{"name":"pandas","slug":"pandas","permalink":"https://onehr7.github.io/tags/pandas/"}]},{"title":"Python装饰器实现日志输出","slug":"Python装饰器实现日志输出","date":"2020-11-20T04:18:02.000Z","updated":"2021-06-07T14:51:55.370Z","comments":true,"path":"2020/11/20/Python装饰器实现日志输出/","link":"","permalink":"https://onehr7.github.io/2020/11/20/Python%E8%A3%85%E9%A5%B0%E5%99%A8%E5%AE%9E%E7%8E%B0%E6%97%A5%E5%BF%97%E8%BE%93%E5%87%BA/","excerpt":"","text":"# -*- coding: utf-8 -*- # @Time : 2020/11/20 11:33 # @Author : Wanghairui # @function: from functools import wraps import logging def _create_logger(): logger = logging.getLogger('LogError') logger.setLevel(logging.ERROR) file_handler = logging.FileHandler(r'./MJlogs.log') log_format = '%(levelname)s %(asctime)s %(message)s' formatter = logging.Formatter(log_format) file_handler.setFormatter(formatter) logger.addHandler(file_handler) return logger def logged(func): @wraps(func) def do_logging(*args, **kwargs): try: return func(*args, **kwargs) except Exception as e: logger = _create_logger() error_msg = 'And error has occurred at /' + func.__name__ + '\\n' logger.exception(error_msg) return e return do_logging","categories":[{"name":"python","slug":"python","permalink":"https://onehr7.github.io/categories/python/"}],"tags":[]},{"title":"Python虚拟环境配置","slug":"Python使用Virtualenv虚拟环境","date":"2020-11-16T14:56:28.000Z","updated":"2022-09-10T12:35:04.240Z","comments":true,"path":"2020/11/16/Python使用Virtualenv虚拟环境/","link":"","permalink":"https://onehr7.github.io/2020/11/16/Python%E4%BD%BF%E7%94%A8Virtualenv%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83/","excerpt":"","text":"安装 virtualenv pip install virtualenv 切换到项目目录下，创建虚拟环境 Windows: virtualenv -p python venv linux: sudo virtualenv -p python3 venv 激活虚拟环境 # windows cd venv/Scripts activate # linux source venv/bin/activate 生成requirement文件 pip freeze > requirements.txt 安装requirements.txt所需的模块 pip install -r requirements.txt 退出虚拟环境 deactivate","categories":[{"name":"python","slug":"python","permalink":"https://onehr7.github.io/categories/python/"}],"tags":[]},{"title":"Python生产者消费者模型","slug":"Python 生产者消费者模型","date":"2020-11-06T15:12:05.000Z","updated":"2021-01-26T14:39:34.559Z","comments":true,"path":"2020/11/06/Python 生产者消费者模型/","link":"","permalink":"https://onehr7.github.io/2020/11/06/Python%20%E7%94%9F%E4%BA%A7%E8%80%85%E6%B6%88%E8%B4%B9%E8%80%85%E6%A8%A1%E5%9E%8B/","excerpt":"","text":"import time import queue import threading class ThreadProductorConsumer(): # 初始化模型 def __init__(self): # 大小为15的缓冲池，用于容纳产品 self.q = queue.Queue(15) self.screen_lock = threading.Semaphore(value=1) def productor(self, product): # 生产者不停的每3秒生产一个产品 while True: self.q.put(product) cur_time = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())) cur_name = threading.current_thread().name # print是线程不安全的,需要信号量确保没有冲突 self.screen_lock.acquire() print(cur_time+\" \" + cur_name + \" 生产了一个产品\", sep='\\n') self.screen_lock.release() time.sleep(3) def consumer(self): # 消费者不停的每2秒消费一个产品 while True: self.q.get() cur_time = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())) cur_name = threading.current_thread().name self.screen_lock.acquire() print(cur_time + \" \" + cur_name + \" 消费了一个产品\", sep='\\n') self.screen_lock.release() time.sleep(2) if __name__ == \"__main__\": tpc = ThreadProductorConsumer() p = \"product\" # 实例化了3个生产者 for i in range(3): t = threading.Thread(target=tpc.productor, args=(p,)) t.start() # 实例化了6个消费者 for j in range(6): v = threading.Thread(target=tpc.consumer) v.start()","categories":[{"name":"python","slug":"python","permalink":"https://onehr7.github.io/categories/python/"}],"tags":[{"name":"并发","slug":"并发","permalink":"https://onehr7.github.io/tags/%E5%B9%B6%E5%8F%91/"}]},{"title":"JavaScript浅析","slug":"JavaScript学习笔记","date":"2020-10-27T08:08:37.000Z","updated":"2021-01-26T14:39:49.667Z","comments":true,"path":"2020/10/27/JavaScript学习笔记/","link":"","permalink":"https://onehr7.github.io/2020/10/27/JavaScript%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"一、数据类型 Number : 整数，浮点数，NaN（Not a Number）,Infinity（无限大） NaN 与任何值都不相同，包括自己，可通过isNaN()函数判断NaN","text":"一、数据类型 Number : 整数，浮点数，NaN（Not a Number）,Infinity（无限大） NaN 与任何值都不相同，包括自己，可通过isNaN()函数判断NaN 字符串 多行字符串：`` 模板字符串 var name = '小明'; var age = 20; var message = `你好, $&amp;#123;name&amp;#125;, 你今年$&amp;#123;age&amp;#125;岁了!`; alert(message); 字符串操作 var s = 'Hello, world!'; // length获取长度 s.length; // 13 // 获取指定位置字符 s[0]; // 'H' // toUpperCase() 字符串全转为大写 // toLowerCase() 字符串全转为小写 // indexOf()搜索指定字符串出现的位置 s.indexOf('world'); // 返回7 //substring()返回指定索引区间的子串 s.substring(0, 5); // 从索引0开始到5（不包括5），返回'hello' 字符串不可变 布尔值 null和undefined，大多数情况下，使用null而不是undefined 二、运算符 ==：比较时会自动转换数据类型 ===：只比较数据类型一致的数据 三、数组 同一数组可以包含不同数据类型 数组操作 //length 获取数组的长度,给length赋值将导致数组长度变化 var arr = [1, 2, 3.14, 'Hello', null, true]; arr.length; // 6 // indexOf 搜索一个指定的元素的位置 arr.indexOf(2); // 1 //切片 slice 截取数组的部分元素，返回一个新的数组 var arr = ['A', 'B', 'C', 'D', 'E', 'F', 'G']; arr.slice(0, 3); // 从索引0开始，到索引3结束，但不包括索引3: ['A', 'B', 'C'] arr.slice(3); // 从索引3开始到结束: ['D', 'E', 'F', 'G'] var aCopy = arr.slice(); // 复制数组 //push() 向数组添加若干元素 //pop() 删除最后一个元素 var arr = [1, 2]; arr.push('A', 'B'); // 返回Array新的长度: 4 arr; // [1, 2, 'A', 'B'] arr.pop(); // pop()返回'B' arr; // [1, 2, 'A'] //unshift() 向数组头部添加若干元素 // shift() 删除数组的第一个元素 //sort() 对数组进行排序，默认顺序 //reverse() 反转数组 //splice()从指定的索引开始删除若干元素，然后再从该位置添加若干元素 var arr = ['Microsoft', 'Apple', 'Yahoo', 'AOL', 'Excite', 'Oracle']; // 从索引2开始删除3个元素,然后再添加两个元素: arr.splice(2, 3, 'Google', 'Facebook'); // 返回删除的元素 ['Yahoo', 'AOL', 'Excite'] arr; // ['Microsoft', 'Apple', 'Google', 'Facebook', 'Oracle'] // 只删除,不添加: arr.splice(2, 2); // ['Google', 'Facebook'] arr; // ['Microsoft', 'Apple', 'Oracle'] // 只添加,不删除: arr.splice(2, 0, 'Google', 'Facebook'); // 返回[],因为没有删除任何元素 arr; // ['Microsoft', 'Apple', 'Google', 'Facebook', 'Oracle'] //concat() 将两个数组连接起来，返回一个新数组 var arr = ['A', 'B', 'C']; arr.concat(1, 2, [3, 4]); // ['A', 'B', 'C', 1, 2, 3, 4] //join() 把当前数组的每个元素都用指定的字符串连接起来，然后返回连接后的字符串 var arr = ['A', 'B', 'C', 1, 2, 3]; arr.join('-'); // 'A-B-C-1-2-3' 四、对象 类似于Python的字典 获取对象属性：对象变量.属性名，person.name 判断是否包含某个属性： in操作符：继承的属性也算 hasOwnProperty(): 不包含继承的属性 五、strict模式 如果一个变量没有通过var声明就使用，则该变量就自动被声明为全局变量 //启用strict 'use strict'; 六、map和set map 代替对象存储键值数据，具有极快的查询速度 var m = new Map(); m.set('Adam', 67); // 覆盖掉上面的Adam值 m.set('Adam', 88); m.get('Adam'); // 88 set 只存值，且值不会重复 // 重复元素被过滤 var s = new Set([1, 2, 3, 3, '3']); s; // Set &amp;#123;1, 2, 3, \"3\"&amp;#125; // 可以重复添加，但不会有效果 s.add(4); s; // Set &amp;#123;1, 2, 3, 4&amp;#125; s.add(4); s; // Set &amp;#123;1, 2, 3, 4&amp;#125; 七、常用方法 forEach() ES5.1标准引入,用于遍历可迭代对象 var a = ['A', 'V', 'C'] a.forEach(function(value,index)&amp;#123; console.log(value) &amp;#125;) // map,参数分别为值，键和map var m = new Map([[1, 'x'], [2, 'y'], [3, 'z']]); m.forEach(function (value, key, map) &amp;#123; console.log(key); &amp;#125;); // set,Set与Array类似，但Set没有索引，因此回调函数的前两个参数都是元素本身 var s = new Set(['A', 'B', 'C']); s.forEach(function (element, sameElement, set) &amp;#123; console.log(element); &amp;#125;); 八、函数 匿名函数：function (x) &#123; ... &#125; 可以传入多于或少于函数定义的参数的个数 关键字arguments：将传入的参数保存为类似于Array rest参数：rest参数写在最后，前面用...标识，用于将多出的参数保存到Array中 let关键字：用于声明局部变量，所声明的变量，只在let命令所在的代码块内有效 const: const来定义常量，const与let都具有块级作用域 解构赋值： //直接对多个变量同时赋值 var [x, y, z] = ['hello', 'JavaScript', 'ES6']; let [x, [y, z]] = ['hello', ['JavaScript', 'ES6']]; let [, , z] = ['hello', 'JavaScript', 'ES6']; // 忽略前两个元素，只对z赋值第三个元素 闭包：返回值为函数的函数 箭头函数：相当于匿名函数 (x, y) => x * x + y * y x => &amp;#123; if (x > 0) &amp;#123; return x * x; &amp;#125; else &amp;#123; return - x * x; &amp;#125; &amp;#125; 九、需要注意的点 JavaScript引擎在行末自动添加分号 全局变量会绑定到window上，不同的JavaScript文件如果使用了相同的全局变量，或者定义了相同名字的顶层函数，都会造成命名冲突，并且很难被发现 返回闭包时，返回函数不要引用任何循环变量，或者后续会发生变化的变量","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://onehr7.github.io/categories/JavaScript/"}],"tags":[]},{"title":"Flask Vue跨域配置","slug":"配置Flask+Vue跨域请求","date":"2020-10-27T00:59:18.000Z","updated":"2022-09-10T12:22:01.411Z","comments":true,"path":"2020/10/27/配置Flask+Vue跨域请求/","link":"","permalink":"https://onehr7.github.io/2020/10/27/%E9%85%8D%E7%BD%AEFlask+Vue%E8%B7%A8%E5%9F%9F%E8%AF%B7%E6%B1%82/","excerpt":"配置Flask# 安装flask_cors pip install flask_cors from flask_cors import * #全局配置 CORS(app, supports_credentials=True)","text":"配置Flask# 安装flask_cors pip install flask_cors from flask_cors import * #全局配置 CORS(app, supports_credentials=True) 配置Vue1.找到config目录下的index.js，在proxyTable下添加配置信息: '/api': &amp;#123; target: 'http://localhost:5000/', //后端接口地址 changeOrigin: true, //是否允许跨越 pathRewrite: &amp;#123; '^/api': 'http://localhost:5000/' //路径重写 &amp;#125; &amp;#125; 2.在axios中，请求地址改为：’api/xxx/xxx’","categories":[{"name":"python","slug":"python","permalink":"https://onehr7.github.io/categories/python/"}],"tags":[{"name":"Web","slug":"Web","permalink":"https://onehr7.github.io/tags/Web/"}]},{"title":"asyncio.Semaphore控制协程并发量","slug":"Python使用asyncio.Semaphore控制协程并发量","date":"2020-10-14T12:29:26.000Z","updated":"2021-01-18T14:57:24.202Z","comments":true,"path":"2020/10/14/Python使用asyncio.Semaphore控制协程并发量/","link":"","permalink":"https://onehr7.github.io/2020/10/14/Python%E4%BD%BF%E7%94%A8asyncio.Semaphore%E6%8E%A7%E5%88%B6%E5%8D%8F%E7%A8%8B%E5%B9%B6%E5%8F%91%E9%87%8F/","excerpt":"","text":"# -*- coding: utf-8 -*- # @Time : 2020/10/12 12:03 # @Author : Wanghairui import asyncio import time async def main(): # 控制并发数 20 sem = asyncio.Semaphore(20) tasks = [asyncio.create_task(print_something(\"c\"+str(i), sem)) for i in range(60)] start = time.perf_counter() await asyncio.gather(*tasks) print(\"运行结束\") res = [t.result() for t in tasks] print(res) elapsed = (time.perf_counter() - start) print(elapsed) async def print_something(thing, sem): async with sem: print(thing) await asyncio.sleep(3) return \"A\" if __name__ == \"__main__\": asyncio.run(main())","categories":[{"name":"python","slug":"python","permalink":"https://onehr7.github.io/categories/python/"}],"tags":[{"name":"协程","slug":"协程","permalink":"https://onehr7.github.io/tags/%E5%8D%8F%E7%A8%8B/"}]},{"title":"hexo指令","slug":"hexo指令","date":"2019-07-27T09:22:22.000Z","updated":"2021-01-11T16:05:33.640Z","comments":true,"path":"2019/07/27/hexo指令/","link":"","permalink":"https://onehr7.github.io/2019/07/27/hexo%E6%8C%87%E4%BB%A4/","excerpt":"","text":"hexo指令预览hexo g hexo s http://localhost:4000/ 发布hexo clean hexo g hexo d","categories":[{"name":"指令","slug":"指令","permalink":"https://onehr7.github.io/categories/%E6%8C%87%E4%BB%A4/"}],"tags":[{"name":"指令","slug":"指令","permalink":"https://onehr7.github.io/tags/%E6%8C%87%E4%BB%A4/"}]}],"categories":[{"name":"Python","slug":"Python","permalink":"https://onehr7.github.io/categories/Python/"},{"name":"ClickHouse","slug":"ClickHouse","permalink":"https://onehr7.github.io/categories/ClickHouse/"},{"name":"Kafka","slug":"Kafka","permalink":"https://onehr7.github.io/categories/Kafka/"},{"name":"大数据","slug":"大数据","permalink":"https://onehr7.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"python","slug":"python","permalink":"https://onehr7.github.io/categories/python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://onehr7.github.io/categories/%E7%88%AC%E8%99%AB/"},{"name":"数据结构","slug":"数据结构","permalink":"https://onehr7.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"JavaScript","slug":"JavaScript","permalink":"https://onehr7.github.io/categories/JavaScript/"},{"name":"指令","slug":"指令","permalink":"https://onehr7.github.io/categories/%E6%8C%87%E4%BB%A4/"}],"tags":[{"name":"字节码","slug":"字节码","permalink":"https://onehr7.github.io/tags/%E5%AD%97%E8%8A%82%E7%A0%81/"},{"name":"ReplacingMergeTree","slug":"ReplacingMergeTree","permalink":"https://onehr7.github.io/tags/ReplacingMergeTree/"},{"name":"ssl","slug":"ssl","permalink":"https://onehr7.github.io/tags/ssl/"},{"name":"PyInstaller","slug":"PyInstaller","permalink":"https://onehr7.github.io/tags/PyInstaller/"},{"name":"selenium","slug":"selenium","permalink":"https://onehr7.github.io/tags/selenium/"},{"name":"并查集","slug":"并查集","permalink":"https://onehr7.github.io/tags/%E5%B9%B6%E6%9F%A5%E9%9B%86/"},{"name":"pandas","slug":"pandas","permalink":"https://onehr7.github.io/tags/pandas/"},{"name":"并发","slug":"并发","permalink":"https://onehr7.github.io/tags/%E5%B9%B6%E5%8F%91/"},{"name":"Web","slug":"Web","permalink":"https://onehr7.github.io/tags/Web/"},{"name":"协程","slug":"协程","permalink":"https://onehr7.github.io/tags/%E5%8D%8F%E7%A8%8B/"},{"name":"指令","slug":"指令","permalink":"https://onehr7.github.io/tags/%E6%8C%87%E4%BB%A4/"}]}